{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "import torchvision.transforms as T\n",
    "import albumentations.pytorch as pytorch\n",
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchmetrics import Accuracy, JaccardIndex, FBetaScore\n",
    "from typing import Any, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# from pytorch_lightning.callbacks import EarlyStopping\n",
    "# from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "# # from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint,EarlyStopping,LearningRateMonitor, LearningRateFinder\n",
    "\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x75c7f57ea5b0>"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from segmentation_models_pytorch.utils import metrics\n",
    "\n",
    "from segmentation_models_pytorch.losses import FocalLoss, DiceLoss, JaccardLoss\n",
    "\n",
    "import re\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "# %matplotlib widget\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rc('font',family='Charter')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shutil\n",
    "\n",
    "\n",
    "# from torchmetrics import BinaryConfusionMatrix\n",
    "import random\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1,\"..\")\n",
    "from utils import read_binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermalDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 stage: str,\n",
    "                 images_path: str,\n",
    "                 augmentation: Any = None,\n",
    "                 preprocessing: Any = None,\n",
    "                 shuffle: bool = True,\n",
    "                 seed: int = 42):\n",
    "\n",
    "        self.__attribute_checking(images_path,\n",
    "                                  stage, shuffle)\n",
    "\n",
    "        self.images_path = images_path\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "        self.stage = stage\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "        self.total_len = None\n",
    "        self._images, self._masks = self.__create_dataset()\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    @staticmethod\n",
    "    def __type_checking(images_path: str,\n",
    "                        stage: str, shuffle: bool) -> None:\n",
    "        assert isinstance(images_path, str)\n",
    "        assert isinstance(stage, str)\n",
    "        assert isinstance(shuffle, bool)\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __path_checking(images_path: str) -> None:\n",
    "        assert os.path.isdir(images_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def __stage_checking(stage: str) -> None:\n",
    "        assert stage in [\"train\", \"test\", \"val\"]\n",
    "\n",
    "    @classmethod\n",
    "    def __attribute_checking(cls, images_path: str,\n",
    "                             stage: str,\n",
    "                             shuffle: bool) -> None:\n",
    "\n",
    "        cls.__type_checking(images_path=images_path,\n",
    "                            stage=stage,\n",
    "                            shuffle=shuffle)\n",
    "\n",
    "        cls.__path_checking(images_path=images_path)\n",
    "\n",
    "        cls.__stage_checking(stage=stage)\n",
    "\n",
    "    def __create_dataset(self) -> dict:\n",
    "        dict_paths = {\n",
    "            \"image\": [],\n",
    "            \"mask\": []\n",
    "        }\n",
    "\n",
    "        images_path = self.__split_data(self.stage)\n",
    "\n",
    "        #### NEED TO ADD SHUFFLE ON HOW THE IMAGES ARE ACCESSED, AND INCLUDE SEED\n",
    "\n",
    "        images_path_shuffle = os.listdir(images_path)\n",
    "        \n",
    "        random.shuffle(images_path_shuffle)\n",
    "\n",
    "        for image_name in images_path_shuffle:\n",
    "            dict_paths[\"image\"].append(os.path.join(images_path,image_name))\n",
    "            dict_paths[\"mask\"].append(os.path.join(os.path.dirname(images_path),'masks',image_name.replace('_NIR_SWIR','_mask')))\n",
    "\n",
    "        dataframe = pd.DataFrame(\n",
    "            data=dict_paths,\n",
    "            index=np.arange(0, len(dict_paths[\"image\"]))\n",
    "        )\n",
    "        self.total_len = len(dataframe)\n",
    "        data_dict = {self.stage: (dataframe[\"image\"].values,dataframe[\"mask\"].values)}\n",
    "\n",
    "        return data_dict[self.stage]\n",
    "\n",
    "    def __split_data(self, stage: str) -> str:\n",
    "        return os.path.join(self.images_path,stage,'images')\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.total_len\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple:\n",
    "\n",
    "        # with open(self._images[idx],'rb') as image_file:\n",
    "        #     image_bin = image_file.read()\n",
    "        #     image = np.frombuffer(image_bin,dtype=np.float32).reshape(256,256,3)\n",
    "        # with open(self._masks[idx],'rb') as mask_file:\n",
    "        #     mask_bin = mask_file.read()\n",
    "        #     mask = np.frombuffer(mask_bin,dtype=np.float32).reshape(256,256,1)\n",
    "\n",
    "        image = read_binary_image(image_path=self._images[idx],\n",
    "                                  dtype=np.float32,\n",
    "                                  shape=[256,256,3])\n",
    "\n",
    "        mask = read_binary_image(image_path=self._masks[idx],\n",
    "                                  dtype=np.float32,\n",
    "                                  shape=[256,256,1])\n",
    "\n",
    "        # image = Image.open(self._images[idx])\n",
    "        # mask = Image.open(self._masks[idx])\n",
    "        \n",
    "        # image = np.array(image)\n",
    "\n",
    "        ### FOR FOCAL LOSS\n",
    "        # mask = mask.convert('L') # This ensures that the label only have 1 band, which is necessary for binary classification\n",
    "        # mask = np.array(mask)[:,:,np.newaxis]\n",
    "        \n",
    "        # mask = np.divide(mask,255).astype('float32') #Masks need to be 0-1 values\n",
    "        \n",
    "        # # apply augmentation\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.01562882, 0.01636142, 0.01562882],\n",
       "         [0.01587302, 0.01489621, 0.01538462],\n",
       "         [0.01538462, 0.01636142, 0.01562882],\n",
       "         ...,\n",
       "         [0.01514042, 0.01562882, 0.01538462],\n",
       "         [0.01538462, 0.01514042, 0.01538462],\n",
       "         [0.01538462, 0.01538462, 0.01538462]],\n",
       " \n",
       "        [[0.01611722, 0.01611722, 0.01562882],\n",
       "         [0.01587302, 0.01587302, 0.01514042],\n",
       "         [0.01514042, 0.01611722, 0.01587302],\n",
       "         ...,\n",
       "         [0.01538462, 0.01562882, 0.01514042],\n",
       "         [0.01538462, 0.01562882, 0.01562882],\n",
       "         [0.01587302, 0.01562882, 0.01587302]],\n",
       " \n",
       "        [[0.01587302, 0.01562882, 0.01611722],\n",
       "         [0.01636142, 0.01660562, 0.01660562],\n",
       "         [0.01611722, 0.01562882, 0.01636142],\n",
       "         ...,\n",
       "         [0.01562882, 0.01587302, 0.01514042],\n",
       "         [0.01562882, 0.01538462, 0.01587302],\n",
       "         [0.01587302, 0.01514042, 0.01587302]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.01636142, 0.01562882, 0.01562882],\n",
       "         [0.01587302, 0.01587302, 0.01562882],\n",
       "         [0.01611722, 0.01538462, 0.01587302],\n",
       "         ...,\n",
       "         [0.01538462, 0.01538462, 0.01538462],\n",
       "         [0.01611722, 0.01514042, 0.01587302],\n",
       "         [0.01587302, 0.01538462, 0.01587302]],\n",
       " \n",
       "        [[0.01562882, 0.01562882, 0.01587302],\n",
       "         [0.01611722, 0.01538462, 0.01587302],\n",
       "         [0.01611722, 0.01538462, 0.01562882],\n",
       "         ...,\n",
       "         [0.01514042, 0.01514042, 0.01538462],\n",
       "         [0.01562882, 0.01489621, 0.01562882],\n",
       "         [0.01538462, 0.01489621, 0.01562882]],\n",
       " \n",
       "        [[0.01587302, 0.01562882, 0.01562882],\n",
       "         [0.01611722, 0.01538462, 0.01562882],\n",
       "         [0.01611722, 0.01562882, 0.01562882],\n",
       "         ...,\n",
       "         [0.01538462, 0.01562882, 0.01538462],\n",
       "         [0.01538462, 0.01538462, 0.01611722],\n",
       "         [0.01538462, 0.01538462, 0.01562882]]], dtype=float32),\n",
       " array([[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       " \n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       " \n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       " \n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       " \n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]], dtype=float32))"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path = '/home/cristopher/Documents/SegTHRawS/datasets/train_geo_split_dataset'\n",
    "ThermalDataset(stage = 'val',images_path=images_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermalDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,images_path: str,\n",
    "                 augmentation: Union[T.Compose, A.Compose],\n",
    "                 preprocessing: Any,\n",
    "                 batch_size: int = 5,\n",
    "                 num_workers: int = os.cpu_count(),\n",
    "                 seed: int = 42):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.images_path = images_path\n",
    "        self.data_train = None\n",
    "        self.data_val = None\n",
    "        self.data_test = None\n",
    "        self.data_predict = None\n",
    "        self.seed = seed\n",
    "\n",
    "        self.train_augmentation = augmentation\n",
    "        self.eval_augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "\n",
    "    def setup(self, stage: str = None) -> None:\n",
    "        self.data_train = ThermalDataset(\n",
    "            images_path=self.images_path,\n",
    "            augmentation=self.train_augmentation,\n",
    "            preprocessing=self.preprocessing,\n",
    "            stage=\"train\",\n",
    "            shuffle=True,\n",
    "            seed=self.seed\n",
    "            )\n",
    "\n",
    "        self.data_val = ThermalDataset(\n",
    "            images_path=self.images_path,\n",
    "            augmentation=self.eval_augmentation,\n",
    "            preprocessing=self.preprocessing,\n",
    "            stage=\"val\",\n",
    "            shuffle=True,\n",
    "            seed=self.seed\n",
    "            )\n",
    "\n",
    "        self.data_test = ThermalDataset(\n",
    "            images_path=self.images_path,\n",
    "            augmentation=self.eval_augmentation,\n",
    "            preprocessing=self.preprocessing,\n",
    "            stage=\"test\",\n",
    "            shuffle=True,\n",
    "            seed=self.seed\n",
    "            )\n",
    "\n",
    "        self.data_predict = ThermalDataset(\n",
    "            images_path=self.images_path,\n",
    "            augmentation=self.eval_augmentation,\n",
    "            preprocessing=self.preprocessing,\n",
    "            stage=\"test\",\n",
    "            shuffle=True,\n",
    "            seed=self.seed\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset=self.data_train,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset=self.data_test,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset=self.data_predict,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ThermalModel(pl.LightningModule):\n",
    "#     def __init__(self,\n",
    "#                  model: nn.Module,\n",
    "#                  loss_fn: Any,\n",
    "#                  optim_dict: dict = None,\n",
    "#                  lr: float = None,\n",
    "#                  num_classes: int = 1):\n",
    "#         super().__init__()\n",
    "#         self.save_hyperparameters(ignore=['model','loss_fn'])\n",
    "\n",
    "#         self.num_classes = num_classes\n",
    "#         self.model = model\n",
    "#         # self.criterion = nn.CrossEntropyLoss()\n",
    "#         self.criterion = loss_fn\n",
    "#         self.optim_dict = optim_dict\n",
    "#         self._device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "#         self.step_outputs = {\n",
    "#             \"loss\": [],\n",
    "#             \"accuracy\": [],\n",
    "#             \"jaccard_index\": [],\n",
    "#             \"fbeta_score\": [],\n",
    "#             \"IoU\": []\n",
    "#         }\n",
    "\n",
    "#         self.metrics = {\n",
    "#             \"accuracy\": Accuracy(task=\"binary\",\n",
    "#                                  threshold=0.5,\n",
    "#                                  num_classes=num_classes,\n",
    "#                                  validate_args=True,\n",
    "#                                  ignore_index=None,\n",
    "#                                  average=\"micro\").to(self._device),\n",
    "\n",
    "#             \"jaccard_index\": JaccardIndex(task=\"binary\",\n",
    "#                                           threshold=0.5,\n",
    "#                                           num_classes=num_classes,\n",
    "#                                           validate_args=True,\n",
    "#                                           ignore_index=None,\n",
    "#                                           average=\"macro\").to(self._device),\n",
    "\n",
    "#             \"fbeta_score\": FBetaScore(task=\"binary\",\n",
    "#                                       beta=1.0,\n",
    "#                                       threshold=0.5,\n",
    "#                                       num_classes=num_classes,\n",
    "#                                       average=\"micro\",\n",
    "#                                       ignore_index=None,\n",
    "#                                       validate_args=True).to(self._device),\n",
    "\n",
    "#             \"IoU\": metrics.IoU()\n",
    "#         }\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "\n",
    "#     def shared_step(self, batch, stage: str) -> torch.Tensor:\n",
    "#         x, y = batch\n",
    "#         x, y = x.to(self._device),y.to(self._device)\n",
    "\n",
    "#         assert x.ndim == 4\n",
    "#         assert x.max() <= 3 and x.min() >= -3 \n",
    "#         assert y.ndim == 4\n",
    "#         assert y.max() <= 1 and y.min() >= 0\n",
    "\n",
    "#         logits = self.forward(x.to(torch.float32))\n",
    "        \n",
    "\n",
    "#         # activated = F.softmax(input=logits, dim=1)\n",
    "#         # predictions = torch.argmax(activated, dim=1)\n",
    "\n",
    "#         predictions = torch.round(torch.sigmoid(logits))\n",
    "#         # predictions = logits\n",
    "        \n",
    "#         loss = self.criterion(logits, y)\n",
    "        \n",
    "#         accuracy = self.metrics[\"accuracy\"](predictions, y)\n",
    "#         jaccard_index = self.metrics[\"jaccard_index\"](predictions, y)\n",
    "#         fbeta_score = self.metrics[\"fbeta_score\"](predictions, y)\n",
    "#         IoU_score = self.metrics[\"IoU\"](predictions, y)\n",
    "\n",
    "#         # print(f'stage: {stage}')\n",
    "#         # print(f'Jaccard: {jaccard_index.dtype}')\n",
    "#         # print(f'loss: {loss.dtype}')\n",
    "\n",
    "#         self.step_outputs[\"loss\"].append(loss)\n",
    "#         self.step_outputs[\"accuracy\"].append(accuracy)\n",
    "#         self.step_outputs[\"jaccard_index\"].append(jaccard_index)\n",
    "#         self.step_outputs[\"fbeta_score\"].append(fbeta_score)\n",
    "#         self.step_outputs[\"IoU\"].append(IoU_score)\n",
    "\n",
    "\n",
    "#         self.log(f'{stage}_loss'   , loss          , prog_bar=True , on_step=False , on_epoch=True)\n",
    "#         # self.log(f'{stage}_acc'    , accuracy      , prog_bar=True , on_step=False , on_epoch=True)\n",
    "#         # self.log(f'{stage}_jaccard', jaccard_index , prog_bar=True , on_step=False , on_epoch=True)\n",
    "#         self.log(f'{stage}_fbeta'  , fbeta_score   , prog_bar=True , on_step=False , on_epoch=True)\n",
    "#         self.log(f'{stage}_IoU'    , IoU_score     , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        \n",
    "#         return loss\n",
    "\n",
    "#     def shared_epoch_end(self, stage: Any):\n",
    "#         loss = torch.mean(torch.tensor([\n",
    "#             loss for loss in self.step_outputs[\"loss\"]\n",
    "#         ]))\n",
    "\n",
    "#         accuracy = torch.mean(torch.tensor([\n",
    "#             accuracy for accuracy in self.step_outputs[\"accuracy\"]\n",
    "#         ]))\n",
    "\n",
    "#         jaccard_index = torch.mean(torch.tensor([\n",
    "#             jaccard_index for jaccard_index in self.step_outputs[\"jaccard_index\"]\n",
    "#         ]))\n",
    "\n",
    "#         print(f'stage: {stage}')\n",
    "#         print(f'jaccard: {self.step_outputs[\"jaccard_index\"]}')\n",
    "#         print(f'Result: {jaccard_index}')\n",
    "\n",
    "\n",
    "#         fbeta_score = torch.mean(torch.tensor(\n",
    "#             [fbeta_score for fbeta_score in self.step_outputs[\"fbeta_score\"]\n",
    "#              ]))\n",
    "\n",
    "#         IoU_score = torch.mean(torch.tensor(\n",
    "#                 [IoU_score for IoU_score in self.step_outputs[\"IoU\"]\n",
    "#                  ]))\n",
    "\n",
    "#         for key in self.step_outputs.keys():\n",
    "#             self.step_outputs[key].clear()\n",
    "\n",
    "#         metrics = {\n",
    "#             f\"{stage}_loss\": loss,\n",
    "#             f\"{stage}_accuracy\": accuracy,\n",
    "#             f\"{stage}_jaccard_index\": jaccard_index,\n",
    "#             f\"{stage}_fbeta_score\": fbeta_score,\n",
    "#             f\"{stage}_IoU\": IoU_score\n",
    "#         }\n",
    "#         self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "#     def training_step(self, batch: Any, batch_idx: Any):\n",
    "#         return self.shared_step(batch=batch, stage=\"train\")\n",
    "\n",
    "#     def on_train_epoch_end(self) -> None:\n",
    "#         return self.shared_epoch_end(stage=\"train\")\n",
    "\n",
    "#     def validation_step(self, batch: Any, batch_idx: Any):\n",
    "#         return self.shared_step(batch=batch, stage=\"val\")\n",
    "\n",
    "#     def on_validation_epoch_end(self) -> None:\n",
    "#         return self.shared_epoch_end(stage=\"val\")\n",
    "\n",
    "#     def test_step(self, batch: Any, batch_idx: Any):\n",
    "#         return self.shared_step(batch=batch, stage=\"test\")\n",
    "\n",
    "#     def on_test_epoch_end(self) -> None:\n",
    "#         return self.shared_epoch_end(stage=\"test\")\n",
    "\n",
    "#     def predict_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0):\n",
    "#         x, y = batch\n",
    "\n",
    "#         assert x.ndim == 4\n",
    "#         assert x.max() <= 3 and x.min() >= -3\n",
    "#         assert y.ndim == 4\n",
    "#         assert y.max() <= 1 and y.min() >= 0\n",
    "\n",
    "#         logits = self.forward(x.to(torch.float32))\n",
    "#         # predictions = logits\n",
    "#         predictions = torch.round(torch.sigmoid(logits))\n",
    "\n",
    "#         # activated = F.softmax(input=logits, dim=1)\n",
    "#         # predictions = torch.argmax(activated, dim=1)\n",
    "\n",
    "#         return predictions\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(\n",
    "#             params=self.parameters(),\n",
    "#             lr=self.hparams.lr\n",
    "#         )\n",
    "\n",
    "#         scheduler_dict = {\n",
    "#             \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#                 optimizer=optimizer,\n",
    "#                 patience=5\n",
    "#             ),\n",
    "#             # \"scheduler\": pl_bolts.optim.lr_scheduler.LinearWarmupCOsineAnnealingLR(\n",
    "#             #     optimizer=optimizer,\n",
    "#             #     warmup_epochs=10,\n",
    "#             #     max_epochs=30,\n",
    "#             # ),\n",
    "#             \"interval\": \"epoch\",\n",
    "#             \"monitor\": \"val_loss\"\n",
    "#         }\n",
    "        \n",
    "#         optimization_dictionary = {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_dict}\n",
    "#         return self.optim_dict if self.optim_dict else optimization_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Combined_Focal_Dice_Loss(pl.LightningModule):\n",
    "    '''\n",
    "    Combined weighted loss between Focal Loss and Dice Loss  \n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 focal_loss_weight: float = 0.5,\n",
    "                 dice_weight: float = None,\n",
    "                 log_dice_loss: bool = False):\n",
    "        \n",
    "        super(Combined_Focal_Dice_Loss, self).__init__()\n",
    "        \n",
    "        self.focal_loss_weight = focal_loss_weight\n",
    "        self.dice_weight = (1 - focal_loss_weight) if dice_weight is None else dice_weight\n",
    "\n",
    "        if self.focal_loss_weight + self.dice_weight != 1:\n",
    "            warnings.warn(\"Sum of Focal and Dice loss weights is not 1.0: \"\n",
    "                          f\"{self.focal_loss_weight:.2f} + {self.dice_weight:.2f} = \"\n",
    "                          f\"{self.focal_loss_weight + self.dice_weight:.2f}\")\n",
    "\n",
    "        self.log_dice_loss = log_dice_loss\n",
    "\n",
    "\n",
    "    # def dice_score(y_pred, y_true, eps=1e-15, smooth=1.):\n",
    "    #     intersection = (y_pred * y_true).sum()\n",
    "    #     union = y_pred.sum() + y_true.sum()\n",
    "    #     return (2. * intersection + smooth) / (union + smooth + eps)\n",
    "\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        focal_loss_fn = FocalLoss(mode= 'binary')\n",
    "        focal_loss_fn.__name__ = 'focal_loss'\n",
    "        dice_loss_fn = DiceLoss(mode= 'binary',from_logits=True,log_loss=self.log_dice_loss) #Typically Dice use the masks and not logits, that is why from logits is used because y_pred are the logits\n",
    "        dice_loss_fn.__name__ = 'dice_loss'\n",
    "\n",
    "\n",
    "        focal_loss = focal_loss_fn(y_pred, y_true) \n",
    "        dice_loss = dice_loss_fn(y_pred, y_true) \n",
    "        \n",
    "        # y_pred = torch.sigmoid(y_pred)\n",
    "        # dice_loss = 1- dice_score(y_pred, y_true)\n",
    "        # log_dice_loss = -torch.log(dice_score(y_pred, y_true))\n",
    "        \n",
    "        loss = self.focal_loss_weight * focal_loss + self.dice_weight * dice_loss\n",
    "\n",
    "        return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ThermalModel(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 loss_fn: Any,\n",
    "                 lr: float = 3e-4,\n",
    "                 num_classes: int = 1,\n",
    "                 batch_size: int = 16):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model','loss_fn'])\n",
    "\n",
    "        \n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.model = model\n",
    "        # self.criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = loss_fn\n",
    "        self._device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "        # self.learning_rate = lr\n",
    "\n",
    "        self.train_outputs = {\n",
    "            \"loss\": [],\n",
    "            \"fbeta_score\": [],\n",
    "            \"IoU\": []\n",
    "        }\n",
    "\n",
    "        self.val_outputs = {\n",
    "            \"loss\": [],\n",
    "            \"fbeta_score\": [],\n",
    "            \"IoU\": []\n",
    "        }\n",
    "\n",
    "        self.example_input_array = torch.zeros((1,3,256,256),dtype = torch.float32)\n",
    "\n",
    "\n",
    "        # self.step_outputs = {\n",
    "        #     \"tp\": [],\n",
    "        #     \"tn\": [],\n",
    "        #     \"fp\": [],\n",
    "        #     \"fn\": []\n",
    "        # }\n",
    "\n",
    "        # self.train_tp = []\n",
    "        # self.train_tn = []\n",
    "        # self.train_fp = []\n",
    "        # self.train_fn = []\n",
    "        \n",
    "        # self.val_tp = []       \n",
    "        # self.val_tn = []\n",
    "        # self.val_fp = []\n",
    "        # self.val_fn = []\n",
    "        \n",
    "        \n",
    "        # self.stage_outputs = {\n",
    "        #     \"train\": self.step_outputs,\n",
    "        #     \"val\": self.step_outputs,\n",
    "        #     \"test\": self.step_outputs\n",
    "        # }\n",
    "\n",
    "        self.metrics = {\n",
    "            \"accuracy\": Accuracy(task=\"binary\",\n",
    "                                 threshold=0.5,\n",
    "                                 num_classes=num_classes,\n",
    "                                 validate_args=True,\n",
    "                                 ignore_index=None,\n",
    "                                 average=\"micro\").to(self._device),\n",
    "\n",
    "            \"jaccard_index\": JaccardIndex(task=\"binary\",\n",
    "                                          threshold=0.5,\n",
    "                                          num_classes=num_classes,\n",
    "                                          validate_args=True,\n",
    "                                          ignore_index=None,\n",
    "                                          average=\"macro\").to(self._device),\n",
    "\n",
    "            \"fbeta_score\": FBetaScore(task=\"binary\",\n",
    "                                      beta=1.0,\n",
    "                                      threshold=0.5,\n",
    "                                      num_classes=num_classes,\n",
    "                                      average=\"micro\",\n",
    "                                      ignore_index=None,\n",
    "                                      validate_args=True).to(self._device),\n",
    "\n",
    "            \"IoU\": metrics.IoU()\n",
    "        }\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.model(x)\n",
    "\n",
    "    # def shared_step(self, batch, stage: str) -> torch.Tensor:\n",
    "    #     x, y = batch\n",
    "    #     x, y = x.to(self._device),y.to(self._device)\n",
    "\n",
    "    #     assert x.ndim == 4\n",
    "    #     assert x.max() <= 3 and x.min() >= -3 \n",
    "    #     assert y.ndim == 4\n",
    "    #     assert y.max() <= 1 and y.min() >= 0\n",
    "\n",
    "    #     logits = self.forward(x.to(torch.float32))\n",
    "        \n",
    "    #     # tensorboard = self.logger.experiment\n",
    "    #     # # tensorboard.add_graph(self.model.state_dict)\n",
    "    #     # tensorboard.add_image('a',y[0],0)\n",
    "\n",
    "\n",
    "\n",
    "    #     # testing  = (torch.softmax(logits, dim=0))\n",
    "    #     testing  = (torch.sigmoid(logits))\n",
    "    #     predictions = (testing > 0.5).float()\n",
    "\n",
    "\n",
    "    #     # tp, fp, fn, tn  = smp.metrics.get_stats(predictions.long(),y.long(),mode = 'binary')\n",
    "\n",
    "    #     # print(predictions)\n",
    "    #     # print(tp,fp,fn,tn)\n",
    "\n",
    "    #     # confmat = BinaryConfusionMatrix()(predictions.detach().cpu(),y.detach().cpu().float())\n",
    "    #     # print(confmat)\n",
    "\n",
    "    #     # print(torch.sum(tp).detach().cpu().numpy(),torch.sum(tn).detach().cpu().numpy(),torch.sum(fp).detach().cpu().numpy(),torch.sum(fn).detach().cpu().numpy())\n",
    "        \n",
    "    #     loss = self.criterion(logits, y)\n",
    "        \n",
    "\n",
    "    #     # print(stage)\n",
    "\n",
    "    #     # accuracy = self.metrics[\"accuracy\"](predictions, y)\n",
    "    #     # jaccard_index = self.metrics[\"jaccard_index\"](predictions, y)\n",
    "    #     fbeta_score = self.metrics[\"fbeta_score\"](predictions, y)\n",
    "    #     IoU_score = self.metrics[\"IoU\"](predictions, y)\n",
    "\n",
    "    #     # self.log(f'{stage}_loss'   , loss          , prog_bar=True , on_step=False , on_epoch=True)\n",
    "    #     # self.log(f'{stage}_fbeta'  , fbeta_score   , prog_bar=True , on_step=False , on_epoch=True)\n",
    "    #     # self.log(f'{stage}_IoU'    , IoU_score     , prog_bar=True , on_step=False , on_epoch=True)\n",
    "\n",
    "\n",
    "    #     metrics = {\n",
    "    #         f\"{stage}_loss_step\": loss,\n",
    "    #         f\"{stage}_fbeta_score_step\": fbeta_score,\n",
    "    #         f\"{stage}_IoU_step\": IoU_score,\n",
    "    #     }\n",
    "    #     self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "    #     self.step_outputs[\"loss\"].append(loss)\n",
    "    #     self.step_outputs[\"fbeta_score\"].append(fbeta_score)\n",
    "    #     self.step_outputs[\"IoU\"].append(IoU_score)\n",
    "\n",
    "        \n",
    "    #     return loss\n",
    "        # print(f'stage: {stage}')\n",
    "        # print(f'Jaccard: {jaccard_index.dtype}')\n",
    "        # print(f'loss: {loss.dtype}')\n",
    "        \n",
    "        # if torch.any(y!=0): # This avoids problems with the empty masks, that provides or 1 IoU or nan Jaccard Index \n",
    "\n",
    "        #     # self.stage_outputs[stage][\"loss\"].append(loss)\n",
    "        #     # self.stage_outputs[stage][\"accuracy\"].append(accuracy)\n",
    "        #     # self.stage_outputs[stage][\"jaccard_index\"].append(jaccard_index)\n",
    "        #     # self.stage_outputs[stage][\"fbeta_score\"].append(fbeta_score)\n",
    "        #     # self.stage_outputs[stage][\"IoU\"].append(IoU_score)\n",
    "\n",
    "\n",
    "        #     self.log(f'{stage}_loss'   , loss          , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        #     self.log(f'{stage}_acc'    , accuracy      , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        #     self.log(f'{stage}_jaccard', jaccard_index , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        #     self.log(f'{stage}_fbeta'  , fbeta_score   , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        #     self.log(f'{stage}_IoU'    , IoU_score     , prog_bar=True , on_step=False , on_epoch=True)\n",
    "\n",
    "            # self.log(f'{stage}_tp'     , tp            , prog_bar=True , on_step=False , on_epoch=True)\n",
    "            # self.log(f'{stage}_fp'     , fp            , prog_bar=True , on_step=False , on_epoch=True)\n",
    "            # self.log(f'{stage}_fn'     , fn            , prog_bar=True , on_step=False , on_epoch=True)\n",
    "            # self.log(f'{stage}_tn'     , tn            , prog_bar=True , on_step=False , on_epoch=True)\n",
    "\n",
    "        # else:\n",
    "            # print(stage,loss,jaccard_index,IoU_score,fbeta_score)\n",
    "            # for i in range(5):\n",
    "            #     plt.figure()\n",
    "            #     plt.subplot(1,2,1)\n",
    "            #     plt.imshow(predictions.detach().cpu().numpy().squeeze()[i,:,:])\n",
    "            #     plt.subplot(1,2,2)\n",
    "            #     plt.imshow(y.detach().cpu().numpy().squeeze()[i,:,:])\n",
    "            #     plt.show()\n",
    "\n",
    "\n",
    "        # self.log(f'{stage}_loss'   , loss          , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        # self.log(f'{stage}_fbeta'  , fbeta_score   , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        # self.log(f'{stage}_IoU'    , IoU_score     , prog_bar=True , on_step=False , on_epoch=True)\n",
    "\n",
    "\n",
    "\n",
    "        # if stage == 'train':\n",
    "        #     self.train_tp.append(torch.sum(tp).detach().cpu().numpy())\n",
    "        #     self.train_tn.append(torch.sum(tn).detach().cpu().numpy())\n",
    "        #     self.train_fp.append(torch.sum(fp).detach().cpu().numpy())\n",
    "        #     self.train_fn.append(torch.sum(fn).detach().cpu().numpy())\n",
    "            \n",
    "        # if stage == 'val':\n",
    "        #     self.val_tp.append(torch.sum(tp).detach().cpu().numpy())\n",
    "        #     self.val_tn.append(torch.sum(tn).detach().cpu().numpy())\n",
    "        #     self.val_fp.append(torch.sum(fp).detach().cpu().numpy())\n",
    "        #     self.val_fn.append(torch.sum(fn).detach().cpu().numpy())\n",
    "\n",
    "        # self.stage_outputs[stage]['tp'].append(torch.sum(tp).detach().cpu().numpy())\n",
    "        # self.stage_outputs[stage]['tn'].append(torch.sum(tn).detach().cpu().numpy())\n",
    "        # self.stage_outputs[stage]['fp'].append(torch.sum(fp).detach().cpu().numpy())\n",
    "        # self.stage_outputs[stage]['fn'].append(torch.sum(fn).detach().cpu().numpy())\n",
    "\n",
    "        # self.log(f'{stage}_tp'     , tp            , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        # self.log(f'{stage}_fp'     , fp            , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        # self.log(f'{stage}_fn'     , fn            , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        # self.log(f'{stage}_tn'     , tn            , prog_bar=True , on_step=False , on_epoch=True)\n",
    "\n",
    "        \n",
    "        # # self.optimizers().step()\n",
    "        # self.lr_schedulers().step()\n",
    "\n",
    "\n",
    "        # return loss\n",
    "\n",
    "        # return {\n",
    "        #     \"loss\": loss,\n",
    "        #     \"tp\": tp,\n",
    "        #     \"fp\": fp,\n",
    "        #     \"fn\": fn,\n",
    "        #     \"tn\": tn,\n",
    "        # }\n",
    "\n",
    "    # def shared_epoch_end(self, stage: Any):\n",
    "\n",
    "    #     print(stage)\n",
    "\n",
    "    #     loss = torch.mean(torch.tensor([\n",
    "    #         loss for loss in self.step_outputs[\"loss\"]\n",
    "    #     ]))\n",
    "\n",
    "    #     print(self.step_outputs)\n",
    "\n",
    "    #     fbeta_score = torch.mean(torch.tensor(\n",
    "    #         [fbeta_score for fbeta_score in self.step_outputs[\"fbeta_score\"]\n",
    "    #          ]))\n",
    "\n",
    "    #     metrics = {\n",
    "    #         f\"{stage}_loss\": loss,\n",
    "    #         f\"{stage}_fbeta_score\": fbeta_score\n",
    "    #     }\n",
    "    #     self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "    #     for key in self.step_outputs.keys():\n",
    "    #         self.step_outputs[key].clear()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: Any):\n",
    "\n",
    "        stage = 'train'\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.to(self._device),y.to(self._device)\n",
    "\n",
    "        assert x.ndim == 4\n",
    "        assert x.max() <= 3 and x.min() >= -3 \n",
    "        assert y.ndim == 4\n",
    "        assert y.max() <= 1 and y.min() >= 0\n",
    "\n",
    "        logits = self.forward(x.to(torch.float32))\n",
    "        \n",
    "        # tensorboard = self.logger.experiment\n",
    "        # # tensorboard.add_graph(self.model.state_dict)\n",
    "        # tensorboard.add_image('a',y[0],0)\n",
    "\n",
    "\n",
    "\n",
    "        # testing  = (torch.softmax(logits, dim=0))\n",
    "        testing  = (torch.sigmoid(logits))\n",
    "        predictions = (testing > 0.5).float()\n",
    "        loss = self.criterion(logits, y)\n",
    "        \n",
    "        fbeta_score = self.metrics[\"fbeta_score\"](predictions, y)\n",
    "        IoU_score = self.metrics[\"IoU\"](predictions, y)\n",
    "\n",
    "        metrics = {\n",
    "            f\"{stage}_loss_step\": loss,\n",
    "            f\"{stage}_fbeta_score_step\": fbeta_score,\n",
    "            f\"{stage}_IoU_step\": IoU_score\n",
    "        }\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "        self.train_outputs[\"loss\"].append(loss)\n",
    "        self.train_outputs[\"fbeta_score\"].append(fbeta_score)\n",
    "        self.train_outputs[\"IoU\"].append(IoU_score)\n",
    "\n",
    "        \n",
    "        return loss\n",
    "\n",
    "        # return self.shared_step(batch=batch, stage=\"train\")\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "\n",
    "        print('train')\n",
    "\n",
    "\n",
    "        loss = torch.mean(torch.tensor([\n",
    "            loss for loss in self.train_outputs[\"loss\"]\n",
    "        ]))\n",
    "\n",
    "\n",
    "        fbeta_score = torch.mean(torch.tensor(\n",
    "            [fbeta_score for fbeta_score in self.train_outputs[\"fbeta_score\"]\n",
    "             ]))\n",
    "\n",
    "        metrics = {\n",
    "            f\"{stage}_loss\": loss,\n",
    "            f\"{stage}_fbeta_score\": fbeta_score\n",
    "        }\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "        for key in self.train_outputs.keys():\n",
    "            self.train_outputs[key].clear()\n",
    "        # return loss\n",
    "\n",
    "        # return self.shared_epoch_end(stage=\"train\")\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: Any):\n",
    "\n",
    "\n",
    "        stage = 'val'\n",
    "\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.to(self._device),y.to(self._device)\n",
    "\n",
    "        assert x.ndim == 4\n",
    "        assert x.max() <= 3 and x.min() >= -3 \n",
    "        assert y.ndim == 4\n",
    "        assert y.max() <= 1 and y.min() >= 0\n",
    "\n",
    "        logits = self.forward(x.to(torch.float32))\n",
    "        \n",
    "        # tensorboard = self.logger.experiment\n",
    "        # # tensorboard.add_graph(self.model.state_dict)\n",
    "        # tensorboard.add_image('a',y[0],0)\n",
    "\n",
    "\n",
    "\n",
    "        # testing  = (torch.softmax(logits, dim=0))\n",
    "        testing  = (torch.sigmoid(logits))\n",
    "        predictions = (testing > 0.5).float()\n",
    "        loss = self.criterion(logits, y)\n",
    "        \n",
    "        fbeta_score = self.metrics[\"fbeta_score\"](predictions, y)\n",
    "        IoU_score = self.metrics[\"IoU\"](predictions, y)\n",
    "\n",
    "        metrics = {\n",
    "            f\"{stage}_loss_step\": loss,\n",
    "            f\"{stage}_fbeta_score_step\": fbeta_score,\n",
    "            f\"{stage}_IoU_step\": IoU_score\n",
    "        }\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "        self.val_outputs[\"loss\"].append(loss)\n",
    "        self.val_outputs[\"fbeta_score\"].append(fbeta_score)\n",
    "        self.val_outputs[\"IoU\"].append(IoU_score)\n",
    "\n",
    "        \n",
    "        return loss\n",
    "\n",
    "        # return self.shared_step(batch=batch, stage=\"val\")\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "\n",
    "        print('val')\n",
    "\n",
    "\n",
    "        loss = torch.mean(torch.tensor([\n",
    "            loss for loss in self.val_outputs[\"loss\"]\n",
    "        ]))\n",
    "\n",
    "\n",
    "        fbeta_score = torch.mean(torch.tensor(\n",
    "            [fbeta_score for fbeta_score in self.val_outputs[\"fbeta_score\"]\n",
    "             ]))\n",
    "\n",
    "        metrics = {\n",
    "            f\"{stage}_loss\": loss,\n",
    "            f\"{stage}_fbeta_score\": fbeta_score\n",
    "        }\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "        for key in self.val_outputs.keys():\n",
    "            self.val_outputs[key].clear()\n",
    "        # return loss\n",
    "        # return self.shared_epoch_end(stage=\"val\")\n",
    "\n",
    "    # def test_step(self, batch: Any, batch_idx: Any):\n",
    "    #     return self.shared_step(batch=batch, stage=\"test\")\n",
    "\n",
    "    # def on_test_epoch_end(self) -> None:\n",
    "    #     return self.shared_epoch_end(stage=\"test\")\n",
    "\n",
    "    def predict_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0):\n",
    "        x, y = batch\n",
    "\n",
    "        assert x.ndim == 4\n",
    "        assert x.max() <= 3 and x.min() >= -3\n",
    "        assert y.ndim == 4\n",
    "        assert y.max() <= 1 and y.min() >= 0\n",
    "\n",
    "        logits = self.forward(x.to(torch.float32))\n",
    "        # predictions = torch.round(logits)\n",
    "        # predictions = torch.round(torch.sigmoid(logits))\n",
    "        \n",
    "        prob_mask = logits.sigmoid()\n",
    "        predictions = (prob_mask > 0.5).float()\n",
    "        # predictions = (logits > 0.5).float()\n",
    "\n",
    "        # activated = F.softmax(input=logits, dim=1)\n",
    "        # predictions = torch.argmax(activated, dim=1)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            params=self.parameters(),\n",
    "            lr=self.hparams.lr\n",
    "        )\n",
    "\n",
    "        scheduler_dict = {\n",
    "            \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer=optimizer,\n",
    "                patience=5\n",
    "            ),\n",
    "            # 'scheduler': torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            #     optimizer=optimizer,\n",
    "            #     T_max=2,\n",
    "            #     eta_min=0.0009\n",
    "            # ),\n",
    "            # \"scheduler\": pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR(\n",
    "            #     optimizer=optimizer,\n",
    "            #     warmup_epochs=2,\n",
    "            #     max_epochs=3,\n",
    "            #     eta_min = 0.001\n",
    "            # ),\n",
    "            # \"interval\": \"step\",\n",
    "            \n",
    "            \"interval\": \"epoch\",\n",
    "            \"monitor\": \"val_loss\"\n",
    "        }\n",
    "        \n",
    "        optimization_dictionary = {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_dict}\n",
    "        return optimization_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "\n",
    "\n",
    "# class Activation(nn.Module):\n",
    "#     def __init__(self, activation, **params):\n",
    "#         super().__init__()\n",
    "\n",
    "#         if activation is None or activation == \"identity\":\n",
    "#             self.activation = nn.Identity(**params)\n",
    "#         elif activation == \"sigmoid\":\n",
    "#             self.activation = nn.Sigmoid()\n",
    "#         elif activation == \"softmax2d\":\n",
    "#             self.activation = nn.Softmax(dim=1, **params)\n",
    "#         elif activation == \"softmax\":\n",
    "#             self.activation = nn.Softmax(**params)\n",
    "#         elif activation == \"logsoftmax\":\n",
    "#             self.activation = nn.LogSoftmax(**params)\n",
    "#         elif activation == \"tanh\":\n",
    "#             self.activation = nn.Tanh()\n",
    "#         elif callable(activation):\n",
    "#             self.activation = activation(**params)\n",
    "#         else:\n",
    "#             raise ValueError(\n",
    "#                 f\"Activation should be callable/sigmoid/softmax/logsoftmax/tanh\"\n",
    "#                 f\"/None; got {activation}\"\n",
    "#             )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.activation(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(callbacks: list,\n",
    "         model: Union[list, tuple],\n",
    "         loss_fn: Any,\n",
    "         augmentation: Any,\n",
    "         preprocessing: Any,\n",
    "         logger: Any,\n",
    "         images_path: str,\n",
    "         optim_dict: dict,\n",
    "         min_epochs: int,\n",
    "         max_epochs: int,\n",
    "         batch_size: int = 16,\n",
    "         precision: str = '16-mixed'\n",
    "         ) -> None:\n",
    "\n",
    "    # Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        fast_dev_run=False,\n",
    "        accelerator=\"auto\",\n",
    "        strategy=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        num_nodes=1,\n",
    "        logger=logger,\n",
    "        callbacks=callbacks,\n",
    "        max_epochs=max_epochs,\n",
    "        min_epochs=min_epochs,\n",
    "        num_sanity_val_steps=0,\n",
    "        precision=precision # Mixed precision training\n",
    "    )\n",
    "\n",
    "    # Datamodule\n",
    "    datamodule = ThermalDataModule(\n",
    "        images_path=images_path,\n",
    "        augmentation=augmentation,\n",
    "        preprocessing=preprocessing,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=os.cpu_count()\n",
    "    )\n",
    "\n",
    "    # LightningModule\n",
    "    lightning_model = ThermalModel(\n",
    "        model=model,\n",
    "        loss_fn=loss_fn,\n",
    "        # lr=3e-4\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.fit(model=lightning_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SegTHRawS',\n",
       " '.git',\n",
       " 'README.md',\n",
       " 'datasets',\n",
       " 'requirements.txt',\n",
       " 'models',\n",
       " 'tree_segthraws_dataset.txt',\n",
       " 'tree_datasets.txt',\n",
       " 'new_THRawS_images',\n",
       " 'segthraws_module']"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.dirname(os.path.dirname(os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Constants\n",
    "SEED: int = 42\n",
    "ACTION: str = \"ignore\"\n",
    "# DATA_PATH: str = os.path.join(os.getcwd(),'train_dataset')\n",
    "# DATA_PATH: str = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'train_dataset')\n",
    "DATA_PATH: str = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'datasets','train_geo_split_dataset')\n",
    "# DATA_PATH: str = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'train_geo_split_dataset')\n",
    "# DATA_PATH: str = os.path.join(os.getcwd(),'train_geo_split_dataset')\n",
    "CHECKPOINT: Any = None\n",
    "    \n",
    "# Model Constants\n",
    "CLASSES = 1\n",
    "IN_CHANNELS = 3\n",
    "\n",
    "optim_dict = None\n",
    "\n",
    "# ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER = 'mobilenet_v2'\n",
    "# ENCODER = 'resnet18'\n",
    "# ENCODER = 'timm-mobilenetv3_large_100'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "    \n",
    "\n",
    "\n",
    "ACTIVATION = None\n",
    "# ACTIVATION = 'sigmoid' # could be None for logits. If used, the sigmoid after the forward function needs to be removed\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "min_epochs = 150\n",
    "max_epochs = 200\n",
    "\n",
    "n_cpu = os.cpu_count()\n",
    "\n",
    "model_name = 'Unet'\n",
    "# model_name = 'DeepLabV3Plus'\n",
    "\n",
    "gamma = 3\n",
    "\n",
    "model_name_path = os.path.join(os.getcwd(),'models',f'{model_name}_{ENCODER}_focal_loss{gamma}_testing')\n",
    "os.makedirs(model_name_path,exist_ok=True)  \n",
    "run_idx =sum(1 for file in os.listdir(model_name_path) if file.startswith('run'))\n",
    "\n",
    "model_main_path = os.path.join(model_name_path,f'run_{run_idx}')\n",
    "os.makedirs(model_main_path,exist_ok=True)\n",
    "\n",
    "# print(model_main_path)\n",
    "\n",
    "# model_main_path = os.path.join(os.getcwd(),'models',f'{model_name}_{ENCODER}_{run_idx}')\n",
    "metrics_path = os.path.join(model_main_path,'metrics')\n",
    "os.makedirs(metrics_path,exist_ok=True)\n",
    "\n",
    "# model = smp.DeepLabV3Plus(\n",
    "#     encoder_name=ENCODER, \n",
    "#     encoder_weights=ENCODER_WEIGHTS, \n",
    "#     classes=1, \n",
    "#     activation=ACTIVATION,\n",
    "# )\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    in_channels = 3,\n",
    "    classes=CLASSES, \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "precision = '16-mixed' # 32 # 32 is the original, and 16 is mixed precission\n",
    "# precision = 32\n",
    "\n",
    "loss = FocalLoss(mode= 'binary',gamma=gamma)\n",
    "loss.__name__ = 'focal_loss'\n",
    "\n",
    "# # loss = DiceLoss(mode= 'binary')\n",
    "# # loss.__name__ = 'dice_loss'\n",
    "\n",
    "# loss = JaccardLoss(mode= 'binary')\n",
    "# loss.__name__ = 'jaccard_loss'\n",
    "\n",
    "# # loss = losses.DiceLoss()\n",
    "# # loss = losses.JaccardLoss()\n",
    "\n",
    "# metrics = [\n",
    "#     metrics.IoU(),\n",
    "# ]\n",
    "\n",
    "# optimizer = torch.optim.Adam([ \n",
    "#     dict(params=model.parameters(), lr=1e-3),\n",
    "# ])\n",
    "\n",
    "augmentation=get_training_augmentation()\n",
    "preprocessing=get_preprocessing(preprocessing_fn)\n",
    "\n",
    "\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.image as mpimg\n",
    "# import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "# ENCODER = 'mobilenet_v2'\n",
    "# ENCODER_WEIGHTS = 'imagenet'\n",
    "\n",
    "# preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "# preprocessing=get_preprocessing(preprocessing_fn)\n",
    "\n",
    "\n",
    "# image_path = '/home/cristopher/Documents/SegTHRawS_training/model_training/train_dataset/test/images/Australia_1_G1_(384, 0, 640, 256)_NIR_SWIR.png'\n",
    "\n",
    "# mean_mobilenet_v2 =  [0.485, 0.456, 0.406]\n",
    "# std_mobilenet_v2 =  [0.229, 0.224, 0.225]\n",
    "\n",
    "# # Define the directory containing the PNG images\n",
    "# image_directory = os.path.join(os.getcwd(),'inputImages')\n",
    "\n",
    "# image = mpimg.imread(image_path)\n",
    "\n",
    "# sample = preprocessing(image=image)\n",
    "# image_processed = sample['image']\n",
    "\n",
    "# # print(np.transpose((image-mean_mobilenet_v2)/std_mobilenet_v2,(2,0,1)))\n",
    "\n",
    "# # print(image_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath=model_main_path,\n",
    "        filename=f\"{model_name}_{ENCODER}_\"+\"{epoch}\",\n",
    "        save_top_k=10,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\"\n",
    "    ),\n",
    "\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-5,\n",
    "        patience=8,\n",
    "        verbose=False,\n",
    "        mode=\"min\"\n",
    "    ),\n",
    "\n",
    "    LearningRateMonitor(\n",
    "        logging_interval=\"step\"\n",
    "    ),\n",
    "\n",
    "    # LearningRateFinder(\n",
    "    #     min_lr = 1e-5,\n",
    "    #     max_lr = 1e-2,\n",
    "    # )\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "logger = TensorBoardLogger(save_dir=\"./logs\", name=model_name,log_graph=True,default_hp_metric=False)\n",
    "\n",
    "\n",
    "\n",
    "# from lightning.pytorch.loggers import CSVLogger\n",
    "# logger = CSVLogger(f\"{model_main_path}/csv_logs\", name=f\"{model_name}_{ENCODER}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Trainer\n",
    "# trainer = pl.Trainer(\n",
    "#     fast_dev_run=False,\n",
    "#     accelerator=\"auto\",\n",
    "#     strategy=\"auto\",\n",
    "#     devices=\"auto\",\n",
    "#     num_nodes=1,\n",
    "#     logger=logger,\n",
    "#     callbacks=callbacks,\n",
    "#     max_epochs=max_epochs,\n",
    "#     min_epochs=min_epochs,\n",
    "#     precision=precision # Mixed precision training\n",
    "# )\n",
    "# # # Datamodule\n",
    "# datamodule = ThermalDataModule(\n",
    "#     images_path=images_path,\n",
    "#     augmentation=augmentation,\n",
    "#     preprocessing=preprocessing,\n",
    "#     batch_size=batch_size,\n",
    "#     num_workers=os.cpu_count()\n",
    "# )\n",
    "\n",
    "# # LightningModule\n",
    "# lightning_model = ThermalModel(\n",
    "#     model=model,\n",
    "#     loss_fn=loss,\n",
    "#     optim_dict=optim_dict,\n",
    "# )\n",
    "\n",
    "# from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "# tuner = Tuner(trainer)\n",
    "\n",
    "# lr_finder = tuner.lr_find(lightning_model,datamodule=datamodule)\n",
    "\n",
    "# new_lr = lr_finder.suggestion()\n",
    "# lightning_model.hparams.lr = new_lr\n",
    "# # # Start training\n",
    "# trainer.fit(model=lightning_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = lr_finder.plot(suggest=True)\n",
    "# fig.show()\n",
    "# # fig.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_lr = tuner.lr_find(lightning_model,datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = final_lr.plot(suggest=True)\n",
    "# fig.show()\n",
    "\n",
    "# new_lr = final_lr.suggestion()\n",
    "\n",
    "# # model.hparams.lr = new_lr\n",
    "# # model.hparams.lr = new_lr\n",
    "# print(new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size_finder = tuner.scale_batch_size(model=lightning_model,datamodule=datamodule,mode='binsearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/cristopher/.local/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:653: Checkpoint directory /home/cristopher/Documents/SegTHRawS/SegTHRawS/model_training/models/Unet_mobilenet_v2_focal_loss3_testing/run_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params | In sizes         | Out sizes       \n",
      "------------------------------------------------------------------------------\n",
      "0 | model     | Unet      | 6.6 M  | [1, 3, 256, 256] | [1, 1, 256, 256]\n",
      "1 | criterion | FocalLoss | 0      | ?                | ?               \n",
      "------------------------------------------------------------------------------\n",
      "6.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 M     Total params\n",
      "26.516    Total estimated model params size (MB)\n",
      "/home/cristopher/.local/lib/python3.10/site-packages/segmentation_models_pytorch/base/model.py:16: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if h % output_stride != 0 or w % output_stride != 0:\n",
      "/home/cristopher/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 24/24 [00:06<00:00,  3.51it/s, v_num=4, train_loss_step=0.0176, train_fbeta_score_step=0.116, train_IoU_step=0.0613]   val\n",
      "{'loss': [tensor(0.1763, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.1295, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.1115, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0837, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0736, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0656, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0587, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0529, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0487, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0440, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0404, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0364, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0328, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0303, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0255, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0232, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0176, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0235, device='cuda:0'), tensor(0.0192, device='cuda:0'), tensor(0.0229, device='cuda:0')], 'fbeta_score': [tensor(0.0020, device='cuda:0'), tensor(0.0029, device='cuda:0'), tensor(0.0019, device='cuda:0'), tensor(0.0033, device='cuda:0'), tensor(0.0029, device='cuda:0'), tensor(0.0036, device='cuda:0'), tensor(0.0053, device='cuda:0'), tensor(0.0013, device='cuda:0'), tensor(0.0153, device='cuda:0'), tensor(0.0103, device='cuda:0'), tensor(0.0145, device='cuda:0'), tensor(0.0148, device='cuda:0'), tensor(0.0139, device='cuda:0'), tensor(0.0131, device='cuda:0'), tensor(0.0014, device='cuda:0'), tensor(0.0544, device='cuda:0'), tensor(0.0887, device='cuda:0'), tensor(0.0113, device='cuda:0'), tensor(0.1138, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.1047, device='cuda:0'), tensor(0.0099, device='cuda:0'), tensor(0.0473, device='cuda:0'), tensor(0.1156, device='cuda:0'), tensor(0.1123, device='cuda:0'), tensor(0.0349, device='cuda:0'), tensor(0.1199, device='cuda:0')], 'IoU': [tensor(0.0010, device='cuda:0'), tensor(0.0014, device='cuda:0'), tensor(0.0010, device='cuda:0'), tensor(0.0016, device='cuda:0'), tensor(0.0015, device='cuda:0'), tensor(0.0018, device='cuda:0'), tensor(0.0027, device='cuda:0'), tensor(0.0006, device='cuda:0'), tensor(0.0077, device='cuda:0'), tensor(0.0052, device='cuda:0'), tensor(0.0073, device='cuda:0'), tensor(0.0075, device='cuda:0'), tensor(0.0070, device='cuda:0'), tensor(0.0066, device='cuda:0'), tensor(0.0007, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0464, device='cuda:0'), tensor(0.0057, device='cuda:0'), tensor(0.0603, device='cuda:0'), tensor(0.0140, device='cuda:0'), tensor(0.0553, device='cuda:0'), tensor(0.0050, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0613, device='cuda:0'), tensor(0.0595, device='cuda:0'), tensor(0.0178, device='cuda:0'), tensor(0.0638, device='cuda:0')]}\n",
      "Epoch 0: 100%|| 24/24 [00:08<00:00,  2.85it/s, v_num=4, train_loss_step=0.0176, train_fbeta_score_step=0.116, train_IoU_step=0.0613, val_loss_step=0.0218, val_fbeta_score_step=0.088, val_IoU_step=0.0464, val_loss=0.0495, val_fbeta_score=0.0351]train\n",
      "{'loss': [], 'fbeta_score': [], 'IoU': []}\n",
      "Epoch 1: 100%|| 24/24 [00:08<00:00,  2.95it/s, v_num=4, train_loss_step=0.00833, train_fbeta_score_step=0.00812, train_IoU_step=0.00407, val_loss_step=0.0218, val_fbeta_score_step=0.088, val_IoU_step=0.0464, val_loss=0.0495, val_fbeta_score=0.0351, train_loss=nan.0, train_fbeta_score=nan.0]val\n",
      "{'loss': [tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0104, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.0083, device='cuda:0'), tensor(0.0069, device='cuda:0'), tensor(0.0078, device='cuda:0')], 'fbeta_score': [tensor(0.0195, device='cuda:0'), tensor(0.0724, device='cuda:0'), tensor(0.0952, device='cuda:0'), tensor(0.2900, device='cuda:0'), tensor(0.2390, device='cuda:0'), tensor(0.1796, device='cuda:0'), tensor(0.1724, device='cuda:0'), tensor(0.3149, device='cuda:0'), tensor(0.1737, device='cuda:0'), tensor(0.0573, device='cuda:0'), tensor(0.2209, device='cuda:0'), tensor(0.3349, device='cuda:0'), tensor(0.1118, device='cuda:0'), tensor(0.1478, device='cuda:0'), tensor(0.3399, device='cuda:0'), tensor(0.2857, device='cuda:0'), tensor(0.3847, device='cuda:0'), tensor(0.2561, device='cuda:0'), tensor(0.2432, device='cuda:0'), tensor(0.0082, device='cuda:0'), tensor(0.3874, device='cuda:0'), tensor(0.0900, device='cuda:0'), tensor(0.2164, device='cuda:0'), tensor(0.0081, device='cuda:0'), tensor(0.0917, device='cuda:0'), tensor(0.0566, device='cuda:0'), tensor(0.1022, device='cuda:0')], 'IoU': [tensor(0.0099, device='cuda:0'), tensor(0.0376, device='cuda:0'), tensor(0.0500, device='cuda:0'), tensor(0.1696, device='cuda:0'), tensor(0.1357, device='cuda:0'), tensor(0.0987, device='cuda:0'), tensor(0.0943, device='cuda:0'), tensor(0.1869, device='cuda:0'), tensor(0.0951, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.1242, device='cuda:0'), tensor(0.2012, device='cuda:0'), tensor(0.0592, device='cuda:0'), tensor(0.0798, device='cuda:0'), tensor(0.2047, device='cuda:0'), tensor(0.1667, device='cuda:0'), tensor(0.2381, device='cuda:0'), tensor(0.1468, device='cuda:0'), tensor(0.1384, device='cuda:0'), tensor(0.0041, device='cuda:0'), tensor(0.2402, device='cuda:0'), tensor(0.0471, device='cuda:0'), tensor(0.1213, device='cuda:0'), tensor(0.0041, device='cuda:0'), tensor(0.0481, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0538, device='cuda:0')]}\n",
      "Epoch 1: 100%|| 24/24 [00:09<00:00,  2.51it/s, v_num=4, train_loss_step=0.00833, train_fbeta_score_step=0.00812, train_IoU_step=0.00407, val_loss_step=0.00767, val_fbeta_score_step=0.0829, val_IoU_step=0.0433, val_loss=0.0101, val_fbeta_score=0.181, train_loss=nan.0, train_fbeta_score=nan.0]train\n",
      "{'loss': [], 'fbeta_score': [], 'IoU': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|| 24/24 [00:09<00:00,  2.46it/s, v_num=4, train_loss_step=0.00833, train_fbeta_score_step=0.00812, train_IoU_step=0.00407, val_loss_step=0.00767, val_fbeta_score_step=0.0829, val_IoU_step=0.0433, val_loss=0.0101, val_fbeta_score=0.181, train_loss=nan.0, train_fbeta_score=nan.0]\n"
     ]
    }
   ],
   "source": [
    "main(\n",
    "    callbacks=callbacks,\n",
    "    model=model,\n",
    "    loss_fn= loss, #Combined_Focal_Dice_Loss(),\n",
    "    augmentation=augmentation,\n",
    "    preprocessing=preprocessing,\n",
    "    logger=logger,\n",
    "    images_path=DATA_PATH,\n",
    "    optim_dict=optim_dict,\n",
    "    min_epochs=2, #min_epochs,\n",
    "    max_epochs=2, #max_epochs\n",
    "    batch_size=60,\n",
    "    precision='16-mixed' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# # %tensorboard --logdir models/current_best_model/version_33\n",
    "\n",
    "# %tensorboard --logdir logs/Unet/version_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# checkpoints_paths = [os.path.join(model_main_path,checkpoint_path) for checkpoint_path in os.listdir(model_main_path) if checkpoint_path[-5:]=='.ckpt']\n",
    "# checkpoint_path = max(checkpoints_paths, key=lambda x: int(re.search(r'epoch=(\\d+)', x).group(1)))\n",
    "\n",
    "# for checkpoint in checkpoints_paths:\n",
    "#     if checkpoint != checkpoint_path:\n",
    "#         os.remove(checkpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### Perform the testing, c  NEED TO create a function\n",
    "# trained_model = ThermalModel.load_from_checkpoint(checkpoint_path=checkpoint_path,model=model,loss_fn=loss)\n",
    "# trained_model.eval();\n",
    "\n",
    "# trainer = pl.Trainer(\n",
    "#     fast_dev_run=False,\n",
    "#     accelerator=\"auto\",\n",
    "#     strategy=\"auto\",\n",
    "#     devices=\"auto\",\n",
    "#     num_nodes=1,\n",
    "#     logger=logger,\n",
    "#     callbacks=callbacks,\n",
    "#     max_epochs=1,\n",
    "#     min_epochs=1,\n",
    "#     precision=precision #Mixed precision training\n",
    "# )\n",
    "\n",
    "# # Datamodule\n",
    "# datamodule = ThermalDataModule(\n",
    "#     images_path=DATA_PATH,\n",
    "#     augmentation=augmentation,\n",
    "#     preprocessing=preprocessing,\n",
    "#     batch_size=12,\n",
    "#     num_workers=os.cpu_count()\n",
    "# )\n",
    "\n",
    "# loss_2 = FocalLoss(mode= 'binary')\n",
    "# loss_2.__name__ = 'focal_loss'\n",
    "\n",
    "# # LightningModule\n",
    "# lightning_model = ThermalModel(\n",
    "#     model=model,\n",
    "#     loss_fn=loss_2,\n",
    "#     optim_dict=optim_dict,\n",
    "#     lr=3e-4\n",
    "# )\n",
    "\n",
    "# test_metrics = trainer.test(model=trained_model,datamodule=datamodule)[0]\n",
    "# # trainer.predict(model=trained_model,datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThermalModel_sigmoid(\n",
       "  (model): ThermalModel(\n",
       "    (model): Unet(\n",
       "      (encoder): MobileNetV2Encoder(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (6): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (7): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (8): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (9): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (10): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (11): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (12): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (13): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (14): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (15): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (16): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (17): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (18): Conv2dNormActivation(\n",
       "            (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder): UnetDecoder(\n",
       "        (center): Identity()\n",
       "        (blocks): ModuleList(\n",
       "          (0): DecoderBlock(\n",
       "            (conv1): Conv2dReLU(\n",
       "              (0): Conv2d(1376, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention1): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "            (conv2): Conv2dReLU(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention2): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "          )\n",
       "          (1): DecoderBlock(\n",
       "            (conv1): Conv2dReLU(\n",
       "              (0): Conv2d(288, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention1): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "            (conv2): Conv2dReLU(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention2): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "          )\n",
       "          (2): DecoderBlock(\n",
       "            (conv1): Conv2dReLU(\n",
       "              (0): Conv2d(152, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention1): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "            (conv2): Conv2dReLU(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention2): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): DecoderBlock(\n",
       "            (conv1): Conv2dReLU(\n",
       "              (0): Conv2d(80, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention1): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "            (conv2): Conv2dReLU(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention2): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "          )\n",
       "          (4): DecoderBlock(\n",
       "            (conv1): Conv2dReLU(\n",
       "              (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention1): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "            (conv2): Conv2dReLU(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention2): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (segmentation_head): SegmentationHead(\n",
       "        (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Identity()\n",
       "        (2): Activation(\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (criterion): FocalLoss()\n",
       "  )\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# class ThermalModel_sigmoid(pl.LightningModule):\n",
    "class ThermalModel_sigmoid(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 model: pl.LightningModule,\n",
    "                 activation: Any = 'sigmoid'):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "\n",
    "        self.model = model\n",
    "        self.metrics  = model.metrics\n",
    "        self._device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation = nn.Sigmoid()\n",
    "\n",
    "    # def Activation(self, activation, **params):\n",
    "    #     if activation == \"sigmoid\":\n",
    "    #         self.activation = nn.Sigmoid()\n",
    "\n",
    "        # elif activation == \"softmax2d\":\n",
    "        #     self.activation = nn.Softmax(dim=1, **params)\n",
    "        # elif activation == \"softmax\":\n",
    "        #     self.activation = nn.Softmax(**params)\n",
    "        # elif activation == \"logsoftmax\":\n",
    "        #     self.activation = nn.LogSoftmax(**params)\n",
    "        # elif activation == \"tanh\":\n",
    "        #     self.activation = nn.Tanh()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Activation should be callable/sigmoid/softmax/logsoftmax/tanh\"\n",
    "                f\"/None; got {activation}\"\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = self.model(x)\n",
    "\n",
    "            output = (self.activation(x)>0.5).float()\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "    def test_step(self, batch: Any, batch_idx: Any):\n",
    "\n",
    "        x, y = batch\n",
    "        x, y = x.to(self._device),y.to(self._device)\n",
    "\n",
    "        assert x.ndim == 4\n",
    "        assert x.max() <= 3 and x.min() >= -3 \n",
    "        assert y.ndim == 4\n",
    "        assert y.max() <= 1 and y.min() >= 0\n",
    "\n",
    "        predictions = self.forward(x.to(torch.float32))\n",
    "        \n",
    "        stage = 'test'\n",
    "\n",
    "        fbeta_score = self.metrics[\"fbeta_score\"](predictions, y)\n",
    "        IoU_score = self.metrics[\"IoU\"](predictions, y)\n",
    "\n",
    "\n",
    "        self.log(f'{stage}_fbeta'  , fbeta_score   , prog_bar=True , on_step=False , on_epoch=True)\n",
    "        self.log(f'{stage}_IoU'    , IoU_score     , prog_bar=True , on_step=False , on_epoch=True)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "new_model = ThermalModel_sigmoid(model=trained_model,activation='sigmoid')\n",
    "new_model\n",
    "\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# image  = mpimg.imread('train_dataset/test/images/Australia_0_G0_(0, 384, 256, 640)_NIR_SWIR.png')\n",
    "\n",
    "# image_model  = np.transpose(image,(2,0,1))[np.newaxis]\n",
    "\n",
    "\n",
    "# new_model(image_model)\n",
    "\n",
    "\n",
    "# torch.save(new_model,os.path.join(model_main_path,'new_model'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model = ThermalModel.load_from_checkpoint(checkpoint_path='models/Unet_mobilenet_v2_metrics_without_empty_masks/Unet_mobilenet_v2_epoch=149.ckpt',model=model,loss_fn=loss)\n",
    "# trained_model.eval();\n",
    "\n",
    "\n",
    "# trained_model = new_model\n",
    "\n",
    "# x = torch.randn(1, 3, 256, 256).cpu()\n",
    "# model_onnx = trained_model.cpu()\n",
    "# model_onnx.eval()\n",
    "\n",
    "# checkpoint_path = '/home/cristopher/Documents/SegTHRawS_training/model_training/models/Unet_mobilenet_v2_metrics_without_empty_masks/Unet_mobilenet_v2_epoch=149.ckpt'\n",
    "# trained_model = ThermalModel.load_from_checkpoint(checkpoint_path=checkpoint_path,model=model,loss_fn=loss)\n",
    "\n",
    "# onnx_model_path = checkpoint_path.replace('.ckpt','.onnx')\n",
    "# onnx_model_path = checkpoint_path.replace('.ckpt','_sigmoid.onnx')\n",
    "# model_onnx = trained_model.cpu()\n",
    "# model_onnx.eval()\n",
    "\n",
    "# torch_out = model_onnx(x)\n",
    "# import warnings\n",
    "# warnings.filterwarnings(category=FutureWarning,action='ignore')\n",
    "# warnings.filterwarnings(category=torch.jit.TracerWarning,action='ignore')\n",
    "\n",
    "\n",
    "# torch.onnx.export(model_onnx,                                   # model being run\n",
    "#                   x,                                            # model input (or a tuple for multiple inputs)\n",
    "#                   onnx_model_path,                              # where to save the model (can be a file or file-like object)\n",
    "#                   export_params=True,                           # store the trained parameter weights inside the model file\n",
    "#                   opset_version=15,                             # the ONNX version to export the model to\n",
    "#                   do_constant_folding=True,                     # whether to execute constant folding for optimization\n",
    "#                   input_names = ['input'],                      # the model's input names\n",
    "#                   output_names = ['output'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# image  = mpimg.imread('train_dataset/test/images/Australia_0_G0_(0, 384, 256, 640)_NIR_SWIR.png')\n",
    "\n",
    "# image_model  = np.transpose(image,(2,0,1))[np.newaxis]\n",
    "\n",
    "\n",
    "# trained_model(image_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThermalModel_sigmoid(\n",
       "  (model): ThermalModel(\n",
       "    (model): Unet(\n",
       "      (encoder): MobileNetV2Encoder(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (6): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (7): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (8): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (9): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (10): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (11): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (12): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (13): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (14): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "                (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (15): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (16): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (17): InvertedResidual(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU6(inplace=True)\n",
       "              )\n",
       "              (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (18): Conv2dNormActivation(\n",
       "            (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder): UnetDecoder(\n",
       "        (center): Identity()\n",
       "        (blocks): ModuleList(\n",
       "          (0): DecoderBlock(\n",
       "            (conv1): Conv2dReLU(\n",
       "              (0): Conv2d(1376, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention1): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "            (conv2): Conv2dReLU(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention2): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "          )\n",
       "          (1): DecoderBlock(\n",
       "            (conv1): Conv2dReLU(\n",
       "              (0): Conv2d(288, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention1): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "            (conv2): Conv2dReLU(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention2): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "          )\n",
       "          (2): DecoderBlock(\n",
       "            (conv1): Conv2dReLU(\n",
       "              (0): Conv2d(152, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention1): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "            (conv2): Conv2dReLU(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention2): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): DecoderBlock(\n",
       "            (conv1): Conv2dReLU(\n",
       "              (0): Conv2d(80, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention1): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "            (conv2): Conv2dReLU(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention2): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "          )\n",
       "          (4): DecoderBlock(\n",
       "            (conv1): Conv2dReLU(\n",
       "              (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention1): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "            (conv2): Conv2dReLU(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (attention2): Attention(\n",
       "              (attention): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (segmentation_head): SegmentationHead(\n",
       "        (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Identity()\n",
       "        (2): Activation(\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (criterion): FocalLoss()\n",
       "  )\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(new_model,os.path.join(model_main_path,'trained_new_model'))\n",
    "\n",
    "# # trained_model = ThermalModel_sigmoid.load_from_checkpoint(checkpoint_path=os.path.join(model_main_path,'trained_new_model'),model=model,loss_fn=loss)\n",
    "\n",
    "\n",
    "# model_2 = torch.load(os.path.join(model_main_path,'trained_new_model'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|| 11/11 [00:00<00:00, 39.94it/s]\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_IoU            0.07021191716194153\n",
      "       test_fbeta           0.12873856723308563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_2.eval()\n",
    "\n",
    "# trainer = pl.Trainer(\n",
    "#     fast_dev_run=False,\n",
    "#     accelerator=\"auto\",\n",
    "#     strategy=\"auto\",\n",
    "#     devices=\"auto\",\n",
    "#     num_nodes=1,\n",
    "#     logger=logger,\n",
    "#     callbacks=callbacks,\n",
    "#     max_epochs=1,\n",
    "#     min_epochs=1,\n",
    "#     precision=precision #Mixed precision training\n",
    "# )\n",
    "\n",
    "# # Datamodule\n",
    "# datamodule = ThermalDataModule(\n",
    "#     images_path=DATA_PATH,\n",
    "#     augmentation=augmentation,\n",
    "#     preprocessing=preprocessing,\n",
    "#     batch_size=16,\n",
    "#     num_workers=os.cpu_count()\n",
    "# )\n",
    "\n",
    "# loss_2 = FocalLoss(mode= 'binary')\n",
    "# loss_2.__name__ = 'focal_loss'\n",
    "\n",
    "# # # LightningModule\n",
    "# # lightning_model = ThermalModel(\n",
    "# #     model=model,\n",
    "# #     loss_fn=loss_2,\n",
    "# #     optim_dict=optim_dict,\n",
    "# #     lr=3e-4\n",
    "# # )\n",
    "\n",
    "# test_metrics = trainer.test(model=model_2,datamodule=datamodule)[0]\n",
    "# # trainer.predict(model=model_2,datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/cristopher/Documents/SegTHRawS/models/unet_smp_mobilenet_v2_fp16_focal_loss_smp_gamma2.0_lr_scheduler_geo_weakly/batch_size_16/seed_0/run_7/seed_0_epoch=78'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_binary_image\n\u001b[1;32m     13\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/cristopher/Documents/SegTHRawS/models/unet_smp_mobilenet_v2_fp16_focal_loss_smp_gamma2.0_lr_scheduler_geo_weakly/batch_size_16/seed_0/run_7/seed_0_epoch=78\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m images_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/cristopher/Documents/SegTHRawS/datasets/train_geo_split_weakly_dataset/test/images\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/cristopher/Documents/SegTHRawS/datasets/train_geo_split_weakly_dataset/test/images/Chillan_Nevados_de_00_G0_(0, 384, 256, 640)_NIR_SWIR.bin\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/cristopher/Documents/SegTHRawS/models/unet_smp_mobilenet_v2_fp16_focal_loss_smp_gamma2.0_lr_scheduler_geo_weakly/batch_size_16/seed_0/run_7/seed_0_epoch=78'"
     ]
    }
   ],
   "source": [
    "# from training_utils import SegTHRawSModel,SegTHRawSDataModule\n",
    "# import torch\n",
    "# import lightning as pl\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import os\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(1,'..')\n",
    "# from utils import read_binary_image\n",
    "\n",
    "# model_path = '/home/cristopher/Documents/SegTHRawS/models/unet_smp_mobilenet_v2_fp16_focal_loss_smp_gamma2.0_lr_scheduler_geo_weakly/batch_size_16/seed_0/run_7/seed_0_epoch=78'\n",
    "\n",
    "# model = torch.load(model_path)\n",
    "\n",
    "# images_path = '/home/cristopher/Documents/SegTHRawS/datasets/train_geo_split_weakly_dataset/test/images'\n",
    "# image_path = '/home/cristopher/Documents/SegTHRawS/datasets/train_geo_split_weakly_dataset/test/images/Chillan_Nevados_de_00_G0_(0, 384, 256, 640)_NIR_SWIR.bin'\n",
    "# mask_path = '/home/cristopher/Documents/SegTHRawS/datasets/train_geo_split_weakly_dataset/test/masks/Chillan_Nevados_de_00_G0_(0, 384, 256, 640)_mask.bin'\n",
    "\n",
    "# for idx,image_name in enumerate(os.listdir(images_path)):\n",
    "#     image_path = os.path.join(images_path,image_name)\n",
    "#     mask_path =  os.path.join(os.path.dirname(images_path),'masks',image_name.replace('NIR_SWIR','mask'))\n",
    "#     image = torch.tensor(read_binary_image(image_path=image_path,dtype=np.float32,shape= [256,256,3]))\n",
    "#     mask  = torch.tensor(read_binary_image(image_path=mask_path,dtype = np.float32, shape= [256,256,1]))\n",
    "\n",
    "#     image_batch = np.transpose(image,(2,0,1))[np.newaxis]\n",
    "#     mask_batch = np.transpose(mask,(2,0,1))[np.newaxis]\n",
    "\n",
    "\n",
    "#     # predictions = model.test_step((image_batch,mask_batch),batch_idx=1)\n",
    "#     predictions = model(image_batch.to('cuda'))\n",
    "\n",
    "#     # test_masks_path = os.path.join(os.path.dirname(os.path.dirname(__file__)),'test_masks_comparison')\n",
    "#     # os.makedirs(test_masks_path,exist_ok=True)\n",
    "\n",
    "#     fig, ax = plt.subplots(1,3,figsize = (9,3))\n",
    "#     prediction_mask = np.transpose(predictions[0].cpu().detach().numpy(),(1,2,0))\n",
    "\n",
    "#     plt.suptitle(f' Test masks comparison', fontsize=14)\n",
    "#     ax[0].imshow(image)\n",
    "#     ax[1].imshow(mask)\n",
    "#     ax[2].imshow(prediction_mask)\n",
    "#     plt.tight_layout()\n",
    "#     # plt.savefig(os.path.join(test_masks_path,f'test_mask_comparison_{self.test_idx+batch_idx}'))\n",
    "#     plt.show()\n",
    "\n",
    "#     if idx>3: break\n",
    "\n",
    "# # model.eval()\n",
    "\n",
    "# # trainer = pl.Trainer(\n",
    "# #     fast_dev_run=False,\n",
    "# #     accelerator=\"auto\",\n",
    "# #     strategy=\"auto\",\n",
    "# #     devices=\"auto\",\n",
    "# #     num_nodes=1,\n",
    "# #     logger=logger,\n",
    "# #     callbacks=callbacks,\n",
    "# #     max_epochs=1,\n",
    "# #     min_epochs=1,\n",
    "# #     precision=precision #Mixed precision training\n",
    "# # )\n",
    "\n",
    "# # # Datamodule\n",
    "# # datamodule = SegTHRawSDataModule(\n",
    "# #     images_path=DATA_PATH,\n",
    "# #     augmentation=augmentation,\n",
    "# #     preprocessing=preprocessing,\n",
    "# #     batch_size=1,\n",
    "# #     num_workers=os.cpu_count()\n",
    "# # )\n",
    "\n",
    "# # loss_2 = FocalLoss(mode= 'binary')\n",
    "# # loss_2.__name__ = 'focal_loss'\n",
    "\n",
    "# # # # LightningModule\n",
    "# # # lightning_model = ThermalModel(\n",
    "# # #     model=model,\n",
    "# # #     loss_fn=loss_2,\n",
    "# # #     optim_dict=optim_dict,\n",
    "# # #     lr=3e-4\n",
    "# # # )\n",
    "\n",
    "\n",
    "\n",
    "# # mask_prediction = trainer.test(model=model,datamodule=datamodule)[0]\n",
    "# # # trainer.predict(model=model_2,datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 183/183 [00:01<00:00, 141.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# # model_ckpt = '/home/cristopher/Documents/SegTHRawS/models/seed_0_epoch=35.ckpt'\n",
    "# model_ckpt = '/home/cristopher/Documents/SegTHRawS/models/seed_0_epoch=24.ckpt'\n",
    "\n",
    "# from training_utils import SegTHRawSModel,SegTHRawSDataModule, SegTHRawSTrainModel, get_training_augmentation, get_preprocessing\n",
    "# import lightning as pl\n",
    "# from models import select_model\n",
    "# from losses import select_loss\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import segmentation_models_pytorch as smp\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# model = select_model(model_name = 'unet_smp',\n",
    "#                 ENCODER = 'mobilenet_v2',\n",
    "#                 ENCODER_WEIGHTS= 'imagenet',\n",
    "#                 ACTIVATION=None)\n",
    "\n",
    "\n",
    "# loss = select_loss(loss_name='focal_loss_smp',weakly=True)\n",
    "\n",
    "# dataset_path = '/home/cristopher/Documents/SegTHRawS/datasets/train_geo_split_weakly_dataset'\n",
    "\n",
    "# preprocessing_fn = smp.encoders.get_preprocessing_fn('mobilenet_v2', 'imagenet')\n",
    "\n",
    "\n",
    "\n",
    "# model_2 = SegTHRawSTrainModel.load_from_checkpoint(checkpoint_path=model_ckpt,model=model,loss_fn = loss)\n",
    "\n",
    "# model_2.eval()\n",
    "\n",
    "# trainer = pl.Trainer(\n",
    "#     fast_dev_run=False,\n",
    "#     accelerator=\"auto\",\n",
    "#     strategy=\"auto\",\n",
    "#     devices=\"auto\",\n",
    "#     num_nodes=1,\n",
    "#     # logger=logger,\n",
    "#     # callbacks=callbacks,\n",
    "#     max_epochs=1,\n",
    "#     min_epochs=1,\n",
    "#     precision='16-mixed', #Mixed precision training\n",
    "    \n",
    "# )\n",
    "\n",
    "# # Datamodule\n",
    "# datamodule = SegTHRawSDataModule(\n",
    "#     images_path=dataset_path,\n",
    "#     augmentation=get_training_augmentation(),\n",
    "#     preprocessing=get_preprocessing(preprocessing_fn=preprocessing_fn),\n",
    "#     batch_size=1,\n",
    "#     num_workers=os.cpu_count()\n",
    "# )\n",
    "\n",
    "\n",
    "# # # LightningModule\n",
    "# # lightning_model = ThermalModel(\n",
    "# #     model=model,\n",
    "# #     loss_fn=loss_2,\n",
    "# #     optim_dict=optim_dict,\n",
    "# #     lr=3e-4\n",
    "# # )\n",
    "\n",
    "# # test_metrics = trainer.test(model=model_2,datamodule=datamodule)[0]\n",
    "# predictions = trainer.predict(model=model_2,datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train_constants import mean_imagenet_imgs, std_imagenet_imgs\n",
    "\n",
    "# for idx,batch in enumerate(predictions):\n",
    "#     image       = np.transpose(batch[0].cpu().detach().numpy()[0],(1,2,0))\n",
    "#     mask        = np.transpose(batch[1].cpu().detach().numpy()[0],(1,2,0))\n",
    "#     prediction_mask  = np.transpose(batch[2].cpu().detach().numpy()[0],(1,2,0))\n",
    "\n",
    "#     image = image*np.array(std_imagenet_imgs) + np.array(mean_imagenet_imgs)\n",
    "#     # image       = np.transpose(image,(1,2,0))\n",
    "\n",
    "#     print(image.shape,mask.shape,prediction_mask.shape)\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots(1,3,figsize = (9,3))\n",
    "\n",
    "#     plt.suptitle(f' Test masks comparison', fontsize=14)\n",
    "#     ax[0].imshow(image)\n",
    "#     ax[1].imshow(mask)\n",
    "#     ax[2].imshow(prediction_mask)\n",
    "#     plt.tight_layout()\n",
    "#     # plt.savefig(os.path.join(test_masks_path,f'test_mask_comparison_{self.test_idx+batch_idx}'))\n",
    "#     plt.show()\n",
    "\n",
    "#     if idx>30: break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
