{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright notice\n",
    "\n",
    "@author Cristopher Castro Traba, Ubotica Technologies\n",
    "\n",
    "@copyright 2024 see license file for details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset verification notebook\n",
    "\n",
    "The goal of this notebook is to provide graphical tools for those that want to check or classify the dataset. These tools include: a visual classification tool for events and potential events, a comparison with the END2END dataset to determine which patches were not included in this dataset and why, and additional tools to see the images and the comparison plots among its masks. Each cell of this notebook has been designed such that they can be run independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification tool for events\n",
    "This tool presents the masks comparison plots for the detected events, and allows the user to classify the image as an event, potential event or not event. The tool considers 50 patches per run, to reduce the workload of the classification user. Additionally, when the tool is stopped and executed again, those events that were already classified don't appear, and only those that are not classified yet. The classfication results are written in a txt file stored in the dataset main directory.\n",
    "\n",
    "The controls of the tool are:\n",
    "- e: classify the patch as event\n",
    "- p: classify the patch as potential event\n",
    "- n: classify the patch as not event\n",
    "- ESC: close the tool\n",
    "\n",
    "In case any other key is pressed, the tool continues in the same image. If an event is misclassified, the only way to do it at the moment is to go to the txt file where you misclassified the event, remove the last line and insert it in the correct txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "from constants import DATASET_PATH\n",
    "\n",
    "\n",
    "# Path to the directory containing images\n",
    "potential_events_dir = os.path.join(DATASET_PATH,'masks','event','comparison','comparison_plot','voting_4')\n",
    "\n",
    "#These lines create the empty txt files\n",
    "Path(os.path.join(DATASET_PATH,'events_list.txt')).touch(exist_ok=True)\n",
    "Path(os.path.join(DATASET_PATH,'not_events_list.txt')).touch(exist_ok=True)\n",
    "Path(os.path.join(DATASET_PATH,'potential_events_list.txt')).touch(exist_ok=True)\n",
    "\n",
    "\n",
    "# Get list of image files in the directory\n",
    "image_files = [f for f in os.listdir(potential_events_dir) if f.endswith(('.png'))]\n",
    "\n",
    "cont =0\n",
    "repeated_condition = False\n",
    "\n",
    "def classify_patch(key,image_file):\n",
    "    repeated_condition = False\n",
    "    misclick_condition = False\n",
    "    break_condition = False\n",
    "\n",
    "    if key == ord('e'):\n",
    "        txt_name = 'events_list.txt' # Events\n",
    "        misclick_condition = False\n",
    "    elif key == ord('n'):\n",
    "        txt_name = 'not_events_list.txt' # Not events\n",
    "        misclick_condition = False\n",
    "    elif key == ord('p'):\n",
    "        txt_name = 'potential_events_list.txt' #Potential events\n",
    "        misclick_condition = False\n",
    "    elif key == 27: #ESC key\n",
    "        break_condition = True\n",
    "\n",
    "    else:\n",
    "        misclick_condition = True\n",
    "\n",
    "    if not misclick_condition and not break_condition:\n",
    "        with open(os.path.join(DATASET_PATH,txt_name),'r+') as f:\n",
    "            for name in f:\n",
    "                if name == f'{image_file}\\n':\n",
    "                    repeated_condition = True\n",
    "                    break\n",
    "            if not repeated_condition:\n",
    "                f.write(f'{image_file}\\n')    \n",
    "    return misclick_condition,break_condition\n",
    "\n",
    "def check_already_classified_patch(image_name):\n",
    "    \n",
    "    already_classified_condition = False\n",
    "    for patch_type in ['events_list.txt','not_events_list.txt','potential_events_list.txt']:\n",
    "\n",
    "        with open(os.path.join(DATASET_PATH,patch_type),'r') as f:\n",
    "            for classified_name in f.readlines():\n",
    "\n",
    "                if image_name == classified_name.rstrip('\\n'):\n",
    "                    already_classified_condition =True\n",
    "                    break\n",
    "    return already_classified_condition\n",
    "\n",
    "cont = 0\n",
    "\n",
    "for image_file in image_files:\n",
    "\n",
    "    already_classified = check_already_classified_patch(image_name=image_file)\n",
    "    \n",
    "    if not already_classified:\n",
    "        image = cv2.imread(os.path.join(potential_events_dir, image_file))\n",
    "        cv2.imshow(f'{image_file[:-4]}', image)\n",
    "    \n",
    "        while True:\n",
    "            key = cv2.waitKey(0)\n",
    "            misclick_condition,break_condition = classify_patch(key,image_file)    \n",
    "            if break_condition: break\n",
    "            if not misclick_condition: break\n",
    "\n",
    "        if break_condition: \n",
    "            cv2.destroyAllWindows()        \n",
    "            break\n",
    "        cv2.destroyAllWindows()\n",
    "        cont +=1\n",
    "        if cont>50:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification tool for potential events\n",
    "This tool presents the masks comparison plots for the detected potential events, and allows the user to classify the image as an event, not event or as unsure potential event. This tool is the same as the previous tool, but changes the classification outputs. In this case, the tool considers 100 patches per run, as there are more potential events than events. Additionally, when the tool is stopped and executed again, those potential events that were already classified don't appear, and only those that are not classified yet. The classfication results are written in a txt file stored in the dataset main directory.\n",
    "\n",
    "The controls of the tool are:\n",
    "- e: classify the patch as event\n",
    "- n: classify the patch as not event\n",
    "- d: classify the patch as unsure potential event\n",
    "- ESC: close the tool\n",
    "\n",
    "In case any other key is pressed, the tool continues in the same image. If an event is misclassified, the only way to do it at the moment is to go to the txt file where you misclassified the event, remove the last line and insert it in the correct txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/cristopher/Desktop/SegTHRawS/datasets/main_dataset/potential_events_list.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m potential_events_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DATASET_PATH,\u001b[39m'\u001b[39m\u001b[39mmasks/potential_events/comparison/comparison_plot/voting_2/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m potential_events_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DATASET_PATH,\u001b[39m'\u001b[39m\u001b[39mmasks\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mpotential_event\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcomparison\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcomparison_plot\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mvoting_2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(DATASET_PATH,\u001b[39m'\u001b[39;49m\u001b[39mpotential_events_list.txt\u001b[39;49m\u001b[39m'\u001b[39;49m),\u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     32\u001b[0m     potential_events_list \u001b[39m=\u001b[39m [re\u001b[39m.\u001b[39mmatch(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(.+)_comparison\u001b[39m\u001b[39m'\u001b[39m,detected_event\u001b[39m.\u001b[39mrstrip())\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m detected_event \u001b[39min\u001b[39;00m file\u001b[39m.\u001b[39mreadlines()]\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m potential_events \u001b[39min\u001b[39;00m potential_events_list:\n\u001b[1;32m     35\u001b[0m     \u001b[39m# print(potential_events_dir,potential_events+'_comparison.png')\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[39m# image = cv2.imread(os.path.join(potential_events_dir,potential_events+'_comparison.png'))\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/cristopher/Desktop/SegTHRawS/datasets/main_dataset/potential_events_list.txt'"
     ]
    }
   ],
   "source": [
    "##### Classify the potential events detected\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from constants import DATASET_PATH\n",
    "cont = 0\n",
    "\n",
    "Path(os.path.join(DATASET_PATH,'unsure_potential_events_list.txt')).touch(exist_ok=True)\n",
    "\n",
    "def check_already_classified_potential_events(image_name):\n",
    "    \n",
    "    already_classified_condition = False\n",
    "    # for patch_type in ['events_list.txt','not_events_list.txt']:\n",
    "    for patch_type in ['events_list.txt','not_events_list.txt','unsure_potential_events_list.txt']:\n",
    "\n",
    "        with open(os.path.join(DATASET_PATH,patch_type),'r') as f:\n",
    "            for classified_name in f.readlines():\n",
    "\n",
    "                if image_name == classified_name.rstrip('\\n'):\n",
    "                    \n",
    "                    already_classified_condition =True\n",
    "                    break\n",
    "    return already_classified_condition\n",
    "\n",
    "events_dir = os.path.join(DATASET_PATH,'masks','event','comparison','comparison_plot','voting_4')\n",
    "\n",
    "potential_events_dir = os.path.join(DATASET_PATH,'masks/potential_events/comparison/comparison_plot/voting_2/')\n",
    "potential_events_dir = os.path.join(DATASET_PATH,'masks','potential_event','comparison','comparison_plot','voting_2')\n",
    "\n",
    "with open(os.path.join(DATASET_PATH,'potential_events_list.txt'),'r') as file:\n",
    "    potential_events_list = [re.match(r'(.+)_comparison',detected_event.rstrip()).group(1) for detected_event in file.readlines()]\n",
    "\n",
    "for potential_events in potential_events_list:\n",
    "    # print(potential_events_dir,potential_events+'_comparison.png')\n",
    "    # image = cv2.imread(os.path.join(potential_events_dir,potential_events+'_comparison.png'))\n",
    "    already_classified = check_already_classified_potential_events(image_name=potential_events)\n",
    "    if not already_classified:\n",
    "        \n",
    "        image = cv2.imread(os.path.join(events_dir,potential_events+'_comparison.png'))\n",
    "        if image is None:\n",
    "            image = cv2.imread(os.path.join(potential_events_dir,potential_events+'_comparison.png'))\n",
    "        cv2.imshow(f'{potential_events}', image)\n",
    "        while True:\n",
    "            key = cv2.waitKey(0)\n",
    "            misclick_condition,break_condition = classify_patch(key,potential_events)\n",
    "            if break_condition: break\n",
    "            if key == ord('e') or key == ord('n'):\n",
    "                with open(os.path.join(DATASET_PATH,'classified_potential_events_list.txt'),'a') as file_1:\n",
    "                    file_1.write(potential_events+'\\n')\n",
    "\n",
    "            if key == ord('d'): \n",
    "\n",
    "                with open(os.path.join(DATASET_PATH,'unsure_potential_events_list.txt'),'a') as file_2:\n",
    "                    file_2.write(potential_events+'\\n')\n",
    "                \n",
    "                break # Go to the next image\n",
    "            if not misclick_condition:\n",
    "                break\n",
    "        if break_condition: \n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        cv2.destroyAllWindows()\n",
    "        cont +=1\n",
    "        if cont>100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comaprison with END2END\n",
    "This cell compares the events that were classified as events with the previous tools and checks if that same patch was included in the events of the END2END database. This ensures that the events already classified in the END2END are also included in this dataset.\n",
    "\n",
    "The problem with the actual dataset is that it was created with a different band alignment than that of END2END, and most of the patches won't coincide. Additionally, the END2END dataset included additional patches that couldn't be detected by this dataset because the corner coordinates do not coincide, as this example: \"Latvia_0_G0_(768, 881, 1024, 1137)_A3492.21.pkl\". The objective with these granules ensured that the events in the borders were fully included. \n",
    "\n",
    "The output of the cell are four lists: correct_events, additional_events, names_not_detected, wrongly_detected and impossible_to_detect. Correct events are those that are included in the END2END dataset, whereas additional_events are those not included. Inside additional_events there are: *impossible_to_detect* to those patches that don't have the same corners as the dataset, *names_not_detected* to those patches that are not marked as events in the actual dataset, and *wrongly_detected* to those name_not_detected patches that are events in the END2END dataset but are classified as potential_event or not_event in the actual dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "191\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(1,'..')\n",
    "from utils import normalize_to_0_to_1,normalize\n",
    "\n",
    "events_txt = os.path.join(os.getcwd(),'dataset','events_list.txt')\n",
    "\n",
    "E2E_database_path = '/home/cristopher/Documents/PyRawS/modifications_cristopher/THRAWS_END2END'\n",
    "\n",
    "train_events_E2E = [os.path.join(E2E_database_path,'TrainVal','event',event_name) for event_name in os.listdir(os.path.join(E2E_database_path,'TrainVal','event'))]\n",
    "test_events_E2E = [os.path.join(E2E_database_path,'Test','event',event_name) for event_name in os.listdir(os.path.join(E2E_database_path,'Test','event'))]\n",
    "\n",
    "events_E2E = train_events_E2E + test_events_E2E\n",
    "\n",
    "correct_events = []\n",
    "additional_events = []\n",
    "names_not_detected = []\n",
    "impossile_to_detect = []\n",
    "wrongly_detected = []\n",
    "break_condition = False\n",
    "\n",
    "\n",
    "\n",
    "for event in events_E2E:\n",
    "    event_name = re.match(r'(.+)_A',os.path.basename(event)).group(1)\n",
    "    with open(events_txt,'r') as file:\n",
    "        \n",
    "        new_events_list = [re.match(r'(.+)_comparison',detected_event.rstrip()).group(1) for detected_event in file.readlines()]\n",
    "    if event_name in new_events_list: \n",
    "        correct_events.append(event)\n",
    "    if event_name not in new_events_list: \n",
    "        additional_events.append(event)\n",
    "\n",
    "        with open(event,'rb') as f:\n",
    "            image = normalize_to_0_to_1(pickle.load(f))\n",
    "        image_name = re.match(r'(.+)_A',os.path.basename(event)).group(1)\n",
    "        \n",
    "        ymin,xmin,ymax,xmax = (np.array(re.findall(r'\\((.+), (.+), (.+), (.+)\\)',os.path.basename(image_name))[0]).astype(int))\n",
    "        \n",
    "        if np.array([ymin%192,xmin%192,(ymax-256)%192,(xmax-256)%192]).any() !=0:\n",
    "            impossile_to_detect.append(event)\n",
    "        else:\n",
    "            names_not_detected.append(event)\n",
    "            \n",
    "            for root,_,files in os.walk(os.path.join(os.getcwd(),'dataset','images')):\n",
    "                for file in files:\n",
    "                    if file == f'{image_name}_NIR_SWIR.pkl':\n",
    "                        wrongly_detected.append(os.path.join(root,file))\n",
    "                        \n",
    "                        with open(os.path.join(root,file), 'rb') as new_file:\n",
    "                            dataset_image = pickle.load(new_file)[:,:,::-1]\n",
    "\n",
    "                        break_condition = True\n",
    "                        break\n",
    "                if break_condition:\n",
    "                    break_condition = False\n",
    "                    break\n",
    "\n",
    "\n",
    "    \n",
    "print(len(correct_events))\n",
    "print(len(names_not_detected), len(wrongly_detected),len(impossile_to_detect))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 61\n",
      "130 191\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(1,'..')\n",
    "from utils import normalize_to_0_to_1,normalize\n",
    "\n",
    "\n",
    "names_not_detected = []\n",
    "impossile_to_detect = []\n",
    "wrongly_detected = []\n",
    "break_condition = False\n",
    "\n",
    "column = np.ones((256,3,3))\n",
    "\n",
    "for event_path in additional_events:\n",
    "    with open(event_path,'rb') as f:\n",
    "        image = normalize_to_0_to_1(pickle.load(f))\n",
    "    image_name = re.match(r'(.+)_A',os.path.basename(event_path)).group(1)\n",
    "    # print(image_name)\n",
    "    ymin,xmin,ymax,xmax = (np.array(re.findall(r'\\((.+), (.+), (.+), (.+)\\)',os.path.basename(image_name))[0]).astype(int))\n",
    "    # print(ymin,xmin,ymax,xmax)\n",
    "    # print(ymin%192,xmin%192,(ymax-256)%192,(xmax-256)%192)\n",
    "    \n",
    "    if np.array([ymin%192,xmin%192,(ymax-256)%192,(xmax-256)%192]).any() !=0:\n",
    "        # print(image_name)\n",
    "\n",
    "        # print(ymin,xmin,ymax,xmax)\n",
    "        # print(ymin%192,xmin%192,(ymax-256)%192,(xmax-256)%192)\n",
    "        impossile_to_detect.append(event_path)\n",
    "    else:\n",
    "\n",
    "        names_not_detected.append(event_path)\n",
    "    # break\n",
    "        \n",
    "\n",
    "        for root,_,files in os.walk(os.path.join(os.getcwd(),'dataset','images')):\n",
    "            for file in files:\n",
    "                if file == f'{image_name}_NIR_SWIR.pkl':\n",
    "                    wrongly_detected.append(os.path.join(root,file))\n",
    "                    \n",
    "                    with open(os.path.join(root,file), 'rb') as new_file:\n",
    "                        dataset_image = pickle.load(new_file)[:,:,::-1]\n",
    "\n",
    "                    break_condition = True\n",
    "                    break\n",
    "            if break_condition:\n",
    "                break_condition = False\n",
    "                break\n",
    "\n",
    "print(len(names_not_detected), len(wrongly_detected))\n",
    "print(len(impossile_to_detect),len(additional_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization tool for events\n",
    "This tool displays the images of the events and if specified by the user, the masks comparison plot of that image.\n",
    "\n",
    "The controls of this tool are:\n",
    "- m: Display the masks comparison plot of the event\n",
    "- n: Advance to the next event\n",
    "- ESC: close the tool\n",
    "\n",
    "In case any other key is pressed, the tool continues in the same image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PART OF THE CODE THAT SHOW THE EVENTS AND THE MASKS\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from constants import DATASET_PATH\n",
    "\n",
    "events_dataset_path = os.path.join(DATASET_PATH,'images','event','NIR_SWIR')\n",
    "comparison_events_dataset_path = os.path.join(DATASET_PATH,'masks','event','comparison','comparison_plot')\n",
    "\n",
    "comparison = False\n",
    "comparison_name = False\n",
    "\n",
    "\n",
    "\n",
    "for event_name in os.listdir(events_dataset_path):\n",
    "    event_path = os.path.join(events_dataset_path,event_name)\n",
    "    with open(event_path,'rb') as event_file:\n",
    "        NIR_SWIR_patch = pickle.load(event_file)\n",
    "    \n",
    "    NIR_SWIR_patch_res = cv2.resize(NIR_SWIR_patch[:,:,::-1],(NIR_SWIR_patch.shape[1]*3,NIR_SWIR_patch.shape[0]*3))\n",
    "    cv2.imshow(f'{event_name}',NIR_SWIR_patch_res)\n",
    "    \n",
    "    key = cv2.waitKey(0)\n",
    "\n",
    "    if key == ord('m'):# Plot masks\n",
    "        comparison_name = re.match(r'(.+)_NIR_SWIR',event_name).group(1)\n",
    "        for root,_,files in os.walk(comparison_events_dataset_path):\n",
    "            for file in files:\n",
    "                if re.match(r'(.+)_comparison',file):\n",
    "                    comparison_plot_name = re.match(r'(.+)_comparison',file).group(1)\n",
    "                    if comparison_plot_name == comparison_name:\n",
    "                        # print(file)\n",
    "                        comparison_image = cv2.imread(os.path.join(root,file))\n",
    "        comparison_image_res = cv2.resize(comparison_image,(int(comparison_image.shape[1]*0.9),int(comparison_image.shape[0]*0.8)))\n",
    "        cv2.imshow(f'{comparison_name} masks',comparison_image_res)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    elif key == 27:# ESC key\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "    elif key == ord('n'):\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f'The key {chr(key)} has not specified a function, try again.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization tool for events\n",
    "This tool displays the images of the potential events and if specified by the user, the masks comparison plot of that image.\n",
    "\n",
    "The controls of this tool are:\n",
    "- m: Display the masks comparison plot of the event\n",
    "- n: Advance to the next event\n",
    "- ESC: close the tool\n",
    "\n",
    "In case any other key is pressed, the tool continues in the same image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PART OF THE CODE THAT SHOW THE POTENTIAL EVENTS AND THEIR RESPECTIVE MASKS\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "events_dataset_path = os.path.join(os.getcwd(),'dataset','images','event','NIR_SWIR')\n",
    "potential_events_dataset_path = os.path.join(os.getcwd(),'dataset','images','potential_event','NIR_SWIR')\n",
    "\n",
    "comparison_events_dataset_path = os.path.join(os.getcwd(),'dataset','masks','events','comparison','comparison_plot')\n",
    "comparison_potential_events_dataset_path = os.path.join(os.getcwd(),'dataset','masks','potential_events','comparison','comparison_plot')\n",
    "\n",
    "comparison = False\n",
    "comparison_name = False\n",
    "\n",
    "with open(os.path.join(os.getcwd(),'dataset','potential_events_list.txt'),'r') as file:\n",
    "    potential_events_list = [re.match(r'(.+)_comparison',detected_event.rstrip()).group(1) for detected_event in file.readlines()]\n",
    "\n",
    "# for event_name in os.listdir(events_dataset_path):\n",
    "for event_name in potential_events_list:\n",
    "    \n",
    "    event_name = event_name +'_NIR_SWIR.pkl'\n",
    "    event_path = os.path.join(events_dataset_path,event_name)\n",
    "    try:\n",
    "        event_path = os.path.join(events_dataset_path,event_name)\n",
    "        with open(event_path,'rb') as event_file:\n",
    "            NIR_SWIR_patch = pickle.load(event_file)\n",
    "    except FileNotFoundError:\n",
    "        event_path = os.path.join(potential_events_dataset_path,event_name)\n",
    "        with open(event_path,'rb') as event_file:\n",
    "           NIR_SWIR_patch = pickle.load(event_file)    \n",
    "\n",
    "    NIR_SWIR_patch_res = cv2.resize(NIR_SWIR_patch[:,:,::-1],(NIR_SWIR_patch.shape[1]*3,NIR_SWIR_patch.shape[0]*3))\n",
    "\n",
    "\n",
    "    cv2.imshow(f'{event_name}',NIR_SWIR_patch_res)\n",
    "    key = cv2.waitKey(0)\n",
    "    # print(key,ord('m'))\n",
    "    if key == ord('m'):# Plot masks\n",
    "        comparison_name = re.match(r'(.+)_NIR_SWIR',event_name).group(1)\n",
    "\n",
    "        \n",
    "        for root,_,files in os.walk(comparison_events_dataset_path):\n",
    "            for file in files:\n",
    "                if re.match(r'(.+)_comparison',file):\n",
    "                    \n",
    "                    comparison_plot_name = re.match(r'(.+)_comparison',file).group(1)\n",
    "                    print(comparison_plot_name,comparison_name)\n",
    "                    if comparison_plot_name == comparison_name:\n",
    "                        print(file)\n",
    "                        comparison_image = cv2.imread(os.path.join(root,file))\n",
    "        comparison_image_res = cv2.resize(comparison_image,(int(comparison_image.shape[1]*0.9),int(comparison_image.shape[0]*0.8)))\n",
    "        cv2.imshow(f'{comparison_name} masks',comparison_image_res)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        # break\n",
    "\n",
    "    \n",
    "    elif key == 27:# ESC key\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    elif key == ord('n'):\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f'The key {chr(key)} has not specified a function, try again.')\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "events_dataset_path = os.path.join(os.getcwd(),'dataset','images','event','NIR_SWIR')\n",
    "potential_events_dataset_path = os.path.join(os.getcwd(),'dataset','images','potential_event','NIR_SWIR')\n",
    "\n",
    "events_path = [os.path.join(events_dataset_path,event_path) for event_path in os.listdir(events_dataset_path)]\n",
    "# potential_events_path = [os.path.join(potential_events_dataset_path,potential_event_path) for potential_event_path in os.listdir(potential_events_dataset_path)]\n",
    "\n",
    "comparison_events_dataset_path = os.path.join(os.getcwd(),'dataset','masks','event','comparison','comparison_plot','voting_intersection')\n",
    "os.makedirs(comparison_events_dataset_path, exist_ok=True)\n",
    "# images_path = events_path + potential_events_path\n",
    "voting_4_path = os.path.join(os.getcwd(),'dataset','masks','event','comparison','voting_4')\n",
    "voting_2_path = os.path.join(os.getcwd(),'dataset','masks','event','comparison','voting_2')\n",
    "voting_3_path = os.path.join(os.getcwd(),'dataset','masks','event','comparison','voting_3')\n",
    "intersection_path = os.path.join(os.getcwd(),'dataset','masks','event','comparison','intersection')\n",
    "\n",
    "for image_path in events_path:\n",
    "    # event_condition = os.path.basename(os.path.dirname(os.path.dirname(image_path)))\n",
    "    image_name = re.match(r'(.+)_NIR_SWIR',os.path.basename(image_path)).group(1)\n",
    "    with open(image_path, 'rb') as event_file:\n",
    "        image = pickle.load(event_file)\n",
    "    \n",
    "    # fig = plt.figure(figsize = (20,40))\n",
    "    fig,ax = plt.subplots(1,5,figsize = (20,4))\n",
    "    cont = 0\n",
    "    fig.suptitle(image_name,fontsize = 20)\n",
    "    # plt.subplot(1,5,cont).set_title('Image')\n",
    "    # plt.imshow(image)\n",
    "    ax[cont].imshow(image)\n",
    "    ax[cont].set_title('Image')\n",
    "    \n",
    "    # cont +=1\n",
    "    # print(image_name)\n",
    "    # break\n",
    "    \n",
    "    \n",
    "    for voting_4_mask_name in os.listdir(voting_4_path):\n",
    "        voting_4_name = re.match(r'(.+)_mask',voting_4_mask_name).group(1)\n",
    "        \n",
    "        if voting_4_name == image_name:\n",
    "            \n",
    "            voting_4_mask_path = os.path.join(voting_4_path,voting_4_mask_name)\n",
    "            with open(voting_4_mask_path,'rb') as voting_4_file:\n",
    "                voting_4_mask = pickle.load(voting_4_file)\n",
    "                ax[1].imshow(voting_4_mask)\n",
    "                ax[1].set_title('Voting 4')\n",
    "\n",
    "            \n",
    "            voting_3_mask_path = os.path.join(voting_3_path,voting_4_name+'_mask_voting_3.pkl')\n",
    "            with open(voting_3_mask_path,'rb') as voting_3_file:\n",
    "                voting_3_mask = pickle.load(voting_3_file)\n",
    "                ax[2].imshow(voting_3_mask)\n",
    "                ax[2].set_title('Voting 3')\n",
    "            voting_2_mask_path = os.path.join(voting_2_path,voting_4_name+'_mask_voting_2.pkl')\n",
    "            with open(voting_2_mask_path,'rb') as voting_2_file:\n",
    "                voting_2_mask = pickle.load(voting_2_file)\n",
    "                ax[3].imshow(voting_2_mask)\n",
    "                ax[3].set_title('Voting 2')\n",
    "            if os.path.isfile(os.path.join(intersection_path,voting_4_name+'_mask_intersection.pkl')):\n",
    "                intersection_mask_path = os.path.join(intersection_path,voting_4_name+'_mask_intersection.pkl')\n",
    "                with open(intersection_mask_path,'rb') as intersection_file:\n",
    "                    intersection_mask = pickle.load(intersection_file)\n",
    "                    ax[4].imshow(intersection_mask)\n",
    "                    ax[4].set_title('Intersection')\n",
    "            else:\n",
    "                intersection_mask = np.zeros((256,256,3))\n",
    "                ax[4].imshow(intersection_mask)\n",
    "                ax[4].set_title('Intersection')\n",
    "            \n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  \n",
    "    \n",
    "\n",
    "\n",
    "    fig.savefig(os.path.join(comparison_events_dataset_path, f'{image_name}_comparison.png'))\n",
    "        # break\n",
    "    plt.close()\n",
    "# comparison_potential_events_dataset_path = os.path.join(os.getcwd(),'dataset','masks','potential_events','comparison','comparison_plot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
